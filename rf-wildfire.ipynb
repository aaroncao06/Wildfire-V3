{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b13321",
   "metadata": {
    "id": "kDQmb5QD9nPW",
    "papermill": {
     "duration": 0.003645,
     "end_time": "2023-10-20T07:59:07.572672",
     "exception": false,
     "start_time": "2023-10-20T07:59:07.569027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12de19c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T07:59:07.581061Z",
     "iopub.status.busy": "2023-10-20T07:59:07.580617Z",
     "iopub.status.idle": "2023-10-20T07:59:59.790805Z",
     "shell.execute_reply": "2023-10-20T07:59:59.789602Z"
    },
    "id": "8GGVQ6bM9sW_",
    "outputId": "755c6265-4f42-4bdb-b3af-97933508ef1a",
    "papermill": {
     "duration": 52.218124,
     "end_time": "2023-10-20T07:59:59.794161",
     "exception": false,
     "start_time": "2023-10-20T07:59:07.576037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.7.0\r\n",
      "Collecting zarr\r\n",
      "  Downloading zarr-2.16.1-py3-none-any.whl (206 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.9/206.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting asciitree (from zarr)\r\n",
      "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.21.0,>=1.20 in /opt/conda/lib/python3.10/site-packages (from zarr) (1.23.5)\r\n",
      "Requirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr) (0.18)\r\n",
      "Collecting numcodecs>=0.10.0 (from zarr)\r\n",
      "  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: asciitree\r\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5050 sha256=cb22c4277b94721cd26cadf27d04ebeded6a2747b72ecc59f17e1b8383fe693e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\r\n",
      "Successfully built asciitree\r\n",
      "Installing collected packages: asciitree, numcodecs, zarr\r\n",
      "Successfully installed asciitree-0.3.3 numcodecs-0.12.1 zarr-2.16.1\r\n",
      "Requirement already satisfied: xarray[io] in /opt/conda/lib/python3.10/site-packages (2023.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.23.5)\r\n",
      "Requirement already satisfied: pandas>=1.4 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.5.3)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (21.3)\r\n",
      "Requirement already satisfied: netCDF4 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.4)\r\n",
      "Collecting h5netcdf (from xarray[io])\r\n",
      "  Downloading h5netcdf-1.2.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.11.1)\r\n",
      "Requirement already satisfied: zarr in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (2.16.1)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (2023.6.0)\r\n",
      "Requirement already satisfied: cftime in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.2)\r\n",
      "Requirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->xarray[io]) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4->xarray[io]) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4->xarray[io]) (2023.3)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from h5netcdf->xarray[io]) (3.9.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from netCDF4->xarray[io]) (2023.5.7)\r\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[io]) (1.4.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[io]) (2.31.0)\r\n",
      "Requirement already satisfied: asciitree in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.3.3)\r\n",
      "Requirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.18)\r\n",
      "Requirement already satisfied: numcodecs>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.12.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.4->xarray[io]) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (1.26.15)\r\n",
      "Installing collected packages: h5netcdf\r\n",
      "Successfully installed h5netcdf-1.2.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!pip install zarr\n",
    "!pip install xarray[io]\n",
    "!pip install -Uqq ipdb\n",
    "from numpy import save, load\n",
    "from pathlib import Path\n",
    "import dask.array as da\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import ipdb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import pandas as pd\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import zarr\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb06fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T07:59:59.806605Z",
     "iopub.status.busy": "2023-10-20T07:59:59.805650Z",
     "iopub.status.idle": "2023-10-20T07:59:59.812237Z",
     "shell.execute_reply": "2023-10-20T07:59:59.811185Z"
    },
    "id": "IexRBIE4w8Mt",
    "outputId": "98c38678-7b06-45c7-e519-63b1c0ed603e",
    "papermill": {
     "duration": 0.015143,
     "end_time": "2023-10-20T07:59:59.814377",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.799234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c832d8",
   "metadata": {
    "id": "YYXjKLYF8o5G",
    "papermill": {
     "duration": 0.004709,
     "end_time": "2023-10-20T07:59:59.824110",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.819401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset + Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056d7a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T07:59:59.838380Z",
     "iopub.status.busy": "2023-10-20T07:59:59.837714Z",
     "iopub.status.idle": "2023-10-20T07:59:59.851859Z",
     "shell.execute_reply": "2023-10-20T07:59:59.850451Z"
    },
    "id": "Dbga3drn8sCE",
    "papermill": {
     "duration": 0.025056,
     "end_time": "2023-10-20T07:59:59.854494",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.829438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TemporalDatasetFromNumpy(Dataset):\n",
    "    def __init__(self, numpy_array, sequence_length, train_ratio, pin_memory):\n",
    "        self.numpy_array = numpy_array #shape (40, 40, 918, 29), lat, lon, time, var\n",
    "        self.sequence_length = sequence_length\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        self.lat_size, self.lon_size, self.time_size, self.num_variables = self.numpy_array.shape\n",
    "\n",
    "        self.time_size -= (sequence_length) #num of timesteps with targets\n",
    "        self.numpy_array = self.numpy_array[:self.time_size]\n",
    "        # 40, 40, 854, 29\n",
    "        # 0 to 39\n",
    "        \n",
    "        self.train_ratio = train_ratio\n",
    "        \n",
    "        self.pos_indices = np.column_stack(np.where(self.numpy_array[:,:,self.sequence_length:, -1] == 1)) \n",
    "        # shape (number_of_occurences) by (lat_indices, lon_indices, time_indices)\n",
    "        self.neg_indices = np.column_stack(np.where(self.numpy_array[:,:,self.sequence_length:, -1] == 0))\n",
    "            \n",
    "        #ipdb.set_trace()\n",
    "        self.total_indices = None\n",
    "        \n",
    "        if (self.train_ratio): # True -> training; False -> eval\n",
    "            \n",
    "            neg_to_pos_ratio = 2\n",
    "            num_rows = len(self.pos_indices)*neg_to_pos_ratio\n",
    "            random_rows = np.random.choice(self.neg_indices.shape[0], size=num_rows, replace=False)\n",
    "            #ipdb.set_trace()\n",
    "            neg_indices_subset = self.neg_indices[random_rows, :]\n",
    "            #ipdb.set_trace()\n",
    "            \n",
    "            self.total_indices = np.concatenate((self.pos_indices, neg_indices_subset), axis=0)\n",
    "            #self.total_indices = np.concatenate((self.pos_indices, self.neg_indices), axis=0)\n",
    "            \n",
    "        else:\n",
    "            self.total_indices = np.concatenate((self.pos_indices, self.neg_indices), axis=0)\n",
    "        \n",
    "        np.random.shuffle(self.total_indices)\n",
    "        #ipdb.set_trace()\n",
    "            \n",
    "    def __len__(self): # num_samples * num_timesteps\n",
    "        return len(self.total_indices)\n",
    "\n",
    "    def __getitem__(self, index): # np array shape (40, 40, 918, 29), lat, lon, time, var\n",
    "        #total indices shape (num samples) by (lat_indices, lon_indices, time_indices)\n",
    "        lat_index = self.total_indices[index, 0]\n",
    "        lon_index = self.total_indices[index, 1]\n",
    "        time_index = self.total_indices[index, 2]\n",
    "\n",
    "        # ex timesteps 0 to 64: 65 timesteps in total, features takes 0 to 63, target is 64th timestep\n",
    "        target_np = self.numpy_array[lat_index, lon_index, time_index+sequence_length, -1] # only last variable gwis_ba\n",
    "        features_np = self.numpy_array[lat_index, lon_index, time_index:time_index+sequence_length, : ] # all variables\n",
    "        # lat, lon, time, var\n",
    "        \n",
    "        \n",
    "        return features_np.squeeze(), target_np.squeeze()\n",
    "\n",
    "def temporal_dataloader(numpy_array, sequence_length, batch_size, train_ratio, pin_memory=False, num_workers=0):\n",
    "    temporal_dataset = TemporalDatasetFromNumpy(numpy_array, sequence_length, train_ratio, pin_memory)\n",
    "    dataloader = DataLoader(temporal_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3b021",
   "metadata": {
    "id": "zmt0TF_39e1Q",
    "papermill": {
     "duration": 0.004774,
     "end_time": "2023-10-20T07:59:59.864644",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.859870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer + Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d937fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T07:59:59.877347Z",
     "iopub.status.busy": "2023-10-20T07:59:59.876917Z",
     "iopub.status.idle": "2023-10-20T07:59:59.889260Z",
     "shell.execute_reply": "2023-10-20T07:59:59.888117Z"
    },
    "id": "Azn6vrTy9iyd",
    "papermill": {
     "duration": 0.021878,
     "end_time": "2023-10-20T07:59:59.891525",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.869647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train(model, dataloader): #each dataloader gives 1203*150 samples\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0.0\n",
    "\n",
    "    for batch_features, batch_target in tqdm(dataloader, desc = 'training'): #ndvi missing values\n",
    "        #ipdb.set_trace()\n",
    "        batch_features = batch_features.numpy()\n",
    "        batch_target = batch_target.numpy()\n",
    "        shape = batch_features.shape\n",
    "        batch_features_reshaped = batch_features.reshape(shape[0],-1)\n",
    "        #Drop all rows containing any nan:\n",
    "        #ipdb.set_trace()\n",
    "        mask = ~np.isnan(batch_features_reshaped).any(axis = 1)\n",
    "        batch_features_reshaped = batch_features_reshaped[mask]\n",
    "        #Reshape back:\n",
    "        #ipdb.set_trace()\n",
    "        batch_features = batch_features_reshaped#.reshape(batch_features_reshaped.shape[0],*shape[1:])\n",
    "        batch_target = batch_target[mask].squeeze()\n",
    "        #ipdb.set_trace()\n",
    "            \n",
    "        model.fit(batch_features, batch_target)\n",
    "        model.n_estimators += 1\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    \n",
    "    total_f1 = 0.0\n",
    "    total_recall = 0.0\n",
    "    total_precision = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_aucroc = 0.0\n",
    "    total_auprc = 0.0\n",
    "    total_samples = 0.0 #because each batch is the same size\n",
    "\n",
    "    for inputs, targets in tqdm(dataloader, desc = 'evaluating'):\n",
    "        inputs = inputs.numpy()\n",
    "        targets = targets.numpy()\n",
    "        shape = inputs.shape\n",
    "        inputs_reshaped = inputs.reshape(shape[0],-1)\n",
    "        #Drop all rows containing any nan:\n",
    "        mask = ~np.isnan(inputs_reshaped).any(axis = 1)\n",
    "        inputs_reshaped = inputs_reshaped[mask]\n",
    "        #ipdb.set_trace()\n",
    "        inputs = inputs_reshaped#.reshape(inputs_reshaped.shape[0],*shape[1:])\n",
    "        targets = targets[mask].squeeze()\n",
    "\n",
    "        outputs = model.predict(inputs)\n",
    "        \n",
    "        num_samples = len(targets)\n",
    "\n",
    "        total_f1 += f1_score(targets, outputs, pos_label=1) * num_samples\n",
    "        total_precision += precision_score(targets, outputs, pos_label=1) * num_samples\n",
    "        total_accuracy += accuracy_score(targets, outputs) * num_samples\n",
    "        total_recall += recall_score(targets, outputs, pos_label=1) * num_samples\n",
    "        total_aucroc += roc_auc_score(targets, outputs) * num_samples\n",
    "        total_auprc += average_precision_score(targets, outputs, pos_label=1) * num_samples\n",
    "        total_samples += num_samples\n",
    "\n",
    "    #average_f1 = total_f1 / total_batches\n",
    "    #average_recall = total_recall / total_batches\n",
    "    #average_precision = total_precision / total_batches\n",
    "    #average_aucroc = total_aucroc / total_batches\n",
    "    #average_accuracy = total_accuracy / total_batches\n",
    "    return total_f1, total_recall, total_precision, total_auprc, total_aucroc, total_accuracy, total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76011bfd",
   "metadata": {
    "id": "3tJV3on_HTSa",
    "papermill": {
     "duration": 0.004301,
     "end_time": "2023-10-20T07:59:59.900884",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.896583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RUN!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3ef50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T07:59:59.912445Z",
     "iopub.status.busy": "2023-10-20T07:59:59.911684Z",
     "iopub.status.idle": "2023-10-20T08:00:02.964471Z",
     "shell.execute_reply": "2023-10-20T08:00:02.963640Z"
    },
    "papermill": {
     "duration": 3.061967,
     "end_time": "2023-10-20T08:00:02.967576",
     "exception": false,
     "start_time": "2023-10-20T07:59:59.905609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 193/193 [00:01<00:00, 127.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "file_path = Path(\"/kaggle/input/california-spatial-temporal-fire-dataset/numpy_california_spatialtemporal_dataset.npy\")\n",
    "numpy_array = np.load(file_path)[:,:,:700,:]\n",
    "model = RandomForestClassifier(n_estimators=100, warm_start = True)\n",
    "sequence_length = 64\n",
    "dataloader = temporal_dataloader(numpy_array, sequence_length, batch_size, train_ratio = True, pin_memory = False, num_workers=0)\n",
    "train(model, dataloader)\n",
    "print('done training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d511c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T08:00:02.983644Z",
     "iopub.status.busy": "2023-10-20T08:00:02.983198Z",
     "iopub.status.idle": "2023-10-20T08:00:11.856108Z",
     "shell.execute_reply": "2023-10-20T08:00:11.855220Z"
    },
    "papermill": {
     "duration": 8.882914,
     "end_time": "2023-10-20T08:00:11.858486",
     "exception": false,
     "start_time": "2023-10-20T08:00:02.975572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 193/193 [00:08<00:00, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4747256177105379\n",
      "0.3753840871251796\n",
      "0.6616192659416837\n",
      "0.4632118727115706\n",
      "0.6399501963913266\n",
      "0.7284315249494793\n",
      "19299.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = temporal_dataloader(np.load(file_path)[:,:,700:,:], sequence_length, batch_size, train_ratio = True, pin_memory = False, num_workers=0)\n",
    "total_f1, total_recall, total_precision, total_auprc, total_aucroc, total_accuracy, total_samples = evaluate_model(model, dataloader)\n",
    "print(total_f1 / total_samples)\n",
    "print(total_recall / total_samples)\n",
    "print(total_precision / total_samples)\n",
    "print(total_auprc / total_samples)\n",
    "print(total_aucroc / total_samples)\n",
    "print(total_accuracy / total_samples)\n",
    "print(total_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.602801,
   "end_time": "2023-10-20T08:00:14.567572",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-20T07:58:56.964771",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
