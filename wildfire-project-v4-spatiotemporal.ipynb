{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{"id":"kDQmb5QD9nPW"}},{"cell_type":"code","source":"!pip install einops\n!pip install zarr\n!pip install xarray[io]\n!pip install -Uqq ipdb\nfrom numpy import save, load\nfrom pathlib import Path\nimport dask.array as da\nimport warnings\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport ipdb\nfrom tqdm import tqdm\nimport torch\nfrom sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score, roc_auc_score, average_precision_score\nimport numpy as np\nfrom torch import nn\nimport math\nfrom torch.optim.optimizer import Optimizer\nimport pandas as pd\nfrom einops import rearrange\nfrom torch.nn import functional as F\nimport xarray as xr\nfrom torch.utils.data import Dataset, DataLoader\nimport zarr\nimport sys\n","metadata":{"id":"8GGVQ6bM9sW_","outputId":"755c6265-4f42-4bdb-b3af-97933508ef1a","execution":{"iopub.status.busy":"2023-07-03T17:47:01.423219Z","iopub.execute_input":"2023-07-03T17:47:01.423752Z","iopub.status.idle":"2023-07-03T17:48:04.365768Z","shell.execute_reply.started":"2023-07-03T17:47:01.423717Z","shell.execute_reply":"2023-07-03T17:48:04.364703Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.6.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting zarr\n  Downloading zarr-2.15.0-py3-none-any.whl (206 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.1/206.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting asciitree (from zarr)\n  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from zarr) (1.23.5)\nRequirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr) (0.18)\nCollecting numcodecs>=0.10.0 (from zarr)\n  Downloading numcodecs-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from numcodecs>=0.10.0->zarr) (0.4)\nBuilding wheels for collected packages: asciitree\n  Building wheel for asciitree (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5050 sha256=61e2e9d5e02caf7322bfd9613ea88a1b2c7fcae0b29c9f385c784754cfc1a4aa\n  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\nSuccessfully built asciitree\nInstalling collected packages: asciitree, numcodecs, zarr\nSuccessfully installed asciitree-0.3.3 numcodecs-0.11.0 zarr-2.15.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: xarray[io] in /opt/conda/lib/python3.10/site-packages (2023.5.0)\nRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.23.5)\nRequirement already satisfied: pandas>=1.4 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.5.3)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (21.3)\nRequirement already satisfied: netCDF4 in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.4)\nCollecting h5netcdf (from xarray[io])\n  Downloading h5netcdf-1.2.0-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.10.1)\nRequirement already satisfied: zarr in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (2.15.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (2023.6.0)\nRequirement already satisfied: cftime in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.2)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from xarray[io]) (1.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->xarray[io]) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4->xarray[io]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4->xarray[io]) (2023.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from h5netcdf->xarray[io]) (3.8.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from netCDF4->xarray[io]) (2023.5.7)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[io]) (1.4.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch->xarray[io]) (2.28.2)\nRequirement already satisfied: asciitree in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.3.3)\nRequirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.18)\nRequirement already satisfied: numcodecs>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from zarr->xarray[io]) (0.11.0)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from numcodecs>=0.10.0->zarr->xarray[io]) (0.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.4->xarray[io]) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->xarray[io]) (1.26.15)\nInstalling collected packages: h5netcdf\nSuccessfully installed h5netcdf-1.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%pdb off","metadata":{"id":"IexRBIE4w8Mt","outputId":"98c38678-7b06-45c7-e519-63b1c0ed603e","execution":{"iopub.status.busy":"2023-07-03T17:48:04.367877Z","iopub.execute_input":"2023-07-03T17:48:04.368762Z","iopub.status.idle":"2023-07-03T17:48:04.377521Z","shell.execute_reply.started":"2023-07-03T17:48:04.368724Z","shell.execute_reply":"2023-07-03T17:48:04.373683Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Automatic pdb calling has been turned OFF\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# support classes for model","metadata":{"id":"PVqM51e6knn_"}},{"cell_type":"code","source":"#from Models.AbsolutePositionalEncoding import tAPE, AbsolutePositionalEncoding, LearnablePositionalEncoding\n#from Models.Attention import Attention, Attention_Rel_Scl, Attention_Rel_Vec\n\ndef get_optimizer(name):\n\n    if name == \"Adam\":\n        return torch.optim.Adam\n    elif name == \"RAdam\":\n        return RAdam\n\ndef get_loss_module():\n    return NoFussCrossEntropyLoss(reduction='none')  # outputs loss for each batch sample\nclass WeightedBCELoss(nn.Module):\n    def __init__(self, pos_weight):\n        super(WeightedBCELoss, self).__init__()\n        self.pos_weight = pos_weight\n\n    def forward(self, inputs, targets):\n        # Compute the weighted BCE loss\n        loss = torch.nn.functional.binary_cross_entropy_with_logits(inputs, targets, pos_weight=self.pos_weight)\n        return loss\n\nclass Permute(nn.Module):\n    def forward(self, x):\n        return x.permute(1, 0, 2)\n\n# from https://github.com/LiyuanLucasLiu/RAdam/blob/master/radam/radam.py\nclass RAdam(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n\n        self.degenerated_to_sgd = degenerated_to_sgd\n        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n            for param in params:\n                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n                    param['buffer'] = [[None, None, None] for _ in range(10)]\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n                        buffer=[[None, None, None] for _ in range(10)])\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('RAdam does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n\n                state['step'] += 1\n                buffered = group['buffer'][int(state['step'] % 10)]\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        step_size = math.sqrt(\n                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    elif self.degenerated_to_sgd:\n                        step_size = 1.0 / (1 - beta1 ** state['step'])\n                    else:\n                        step_size = -1\n                    buffered[2] = step_size\n\n                # more conservative since it's an approximated value\n                if N_sma >= 5:\n                    if group['weight_decay'] != 0:\n                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    p_data_fp32.addcdiv_(exp_avg, denom, value=-step_size * group['lr'])\n                    p.data.copy_(p_data_fp32)\n                elif step_size > 0:\n                    if group['weight_decay'] != 0:\n                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n                    p_data_fp32.add_(exp_avg, alpha=-step_size * group['lr'])\n                    p.data.copy_(p_data_fp32)\n\n        return loss\n\nclass tAPE(nn.Module):\n    r\"\"\"Inject some information about the relative or absolute position of the tokens\n        in the sequence. The positional encodings have the same dimension as\n        the embeddings, so that the two can be summed. Here, we use sine and cosine\n        functions of different frequencies.\n    .. math::\n        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n        \\text{where pos is the word position and i is the embed idx)\n    Args:\n        d_model: the embed dim (required).\n        dropout: the dropout value (default=0.1).\n        max_len: the max. length of the incoming sequence (default=1024).\n    \"\"\"\n\n    def __init__(self, d_model, dropout=0.1, max_len=1024, scale_factor=1.0):\n        super(tAPE, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)  # positional encoding\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n\n        pe[:, 0::2] = torch.sin((position * div_term)*(d_model/max_len))\n        pe[:, 1::2] = torch.cos((position * div_term)*(d_model/max_len))\n        pe = scale_factor * pe.unsqueeze(0)\n        self.register_buffer('pe', pe)  # this stores the variable in the state_dict (used for non-trainable variables)\n\n    def forward(self, x):\n        r\"\"\"Inputs of forward function\n        Args:\n            x: the sequence fed to the positional encoder model (required).\n        Shape:\n            x: [sequence length, batch size, embed dim]\n            output: [sequence length, batch size, embed dim]\n        \"\"\"\n        x = x + self.pe\n        return self.dropout(x)\n\nclass Attention_Rel_Scl(nn.Module):\n    def __init__(self, emb_size, num_heads, seq_len, dropout):\n        super().__init__()\n        self.seq_len = seq_len\n        self.num_heads = num_heads\n        self.scale = emb_size ** -0.5\n        # self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n        self.key = nn.Linear(emb_size, emb_size, bias=False)\n        self.value = nn.Linear(emb_size, emb_size, bias=False)\n        self.query = nn.Linear(emb_size, emb_size, bias=False)\n\n        self.relative_bias_table = nn.Parameter(torch.zeros((2 * self.seq_len - 1), num_heads))\n        coords = torch.meshgrid((torch.arange(1), torch.arange(self.seq_len)))\n        coords = torch.flatten(torch.stack(coords), 1)\n        relative_coords = coords[:, :, None] - coords[:, None, :]\n        relative_coords[1] += self.seq_len - 1\n        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n        self.register_buffer(\"relative_index\", relative_index)\n\n        self.dropout = nn.Dropout(dropout)\n        self.to_out = nn.LayerNorm(emb_size)\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        k = self.key(x).reshape(batch_size, seq_len, self.num_heads, -1).permute(0, 2, 3, 1)\n        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n        # k,v,q shape = (batch_size, num_heads, seq_len, d_head)\n\n        attn = torch.matmul(q, k) * self.scale\n        # attn shape (seq_len, seq_len)\n        attn = nn.functional.softmax(attn, dim=-1)\n\n        # Use \"gather\" for more efficiency on GPUs\n        relative_bias = self.relative_bias_table.gather(0, self.relative_index.repeat(1, 8))\n        relative_bias = rearrange(relative_bias, '(h w) c -> 1 c h w', h=1 * self.seq_len, w=1 * self.seq_len)\n        attn = attn + relative_bias\n\n        # distance_pd = pd.DataFrame(relative_bias[0,0,:,:].cpu().detach().numpy())\n        # distance_pd.to_csv('scalar_position_distance.csv')\n\n        out = torch.matmul(attn, v)\n        # out.shape = (batch_size, num_heads, seq_len, d_head)\n        out = out.transpose(1, 2)\n        # out.shape == (batch_size, seq_len, num_heads, d_head)\n        out = out.reshape(batch_size, seq_len, -1)\n        # out.shape == (batch_size, seq_len, d_model)\n        out = self.to_out(out)\n        return out\n\nclass NoFussCrossEntropyLoss(nn.CrossEntropyLoss):\n    \"\"\"\n    pytorch's CrossEntropyLoss is fussy: 1) needs Long (int64) targets only, and 2) only 1D.\n    This function satisfies these requirements\n    \"\"\"\n\n    def forward(self, inp, target):\n        return F.cross_entropy(inp, target.long(), weight=self.weight,\n                               ignore_index=self.ignore_index, reduction=self.reduction)","metadata":{"id":"Ph9O6vPDkr98","execution":{"iopub.status.busy":"2023-07-03T17:48:04.379139Z","iopub.execute_input":"2023-07-03T17:48:04.379505Z","iopub.status.idle":"2023-07-03T17:48:04.438569Z","shell.execute_reply.started":"2023-07-03T17:48:04.379472Z","shell.execute_reply":"2023-07-03T17:48:04.437557Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Temporal ConvTran Model","metadata":{"id":"vbmlAJ-18yIJ"}},{"cell_type":"code","source":"\nclass SpatioTemporalConvTran(nn.Module):\n    def __init__(self, config, num_classes): # config needs 'Data_shape', 'emb_size', 'num_heads', 'dim_ff'\n        super().__init__()\n        # Parameters Initialization -----------------------------------------------\n        channel_size, seq_len = config['Data_shape'][1], config['Data_shape'][2]\n        temporal_channel_size = 128\n        emb_size = config['emb_size']\n        num_heads = config['num_heads']\n        dim_ff = config['dim_ff']\n        # Embedding Layer -----------------------------------------------------------\n        \n        #shape input: samples features timestep lat lon \n        #kernel shape depth height width\n    \n        self.spatial_convolution = nn.Conv3d(channel_size, temporal_channel_size, kernel_size = (1,3,3), stride=1, padding='valid')\n        \n        #now shape: samples outchannels timesteps 1 1\n        \n        #shape of their input is batch_size, feature_size, sequence_len\n        \n        self.input_normalization = nn.BatchNorm1d(temporal_channel_size, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n        self.embed_layer = nn.Sequential(nn.Conv2d(1, emb_size*4, kernel_size=(1, 8), padding='same'),\n                                         nn.BatchNorm2d(emb_size*4),\n                                         nn.GELU())\n\n        self.embed_layer2 = nn.Sequential(nn.Conv2d(emb_size*4, emb_size, kernel_size=[temporal_channel_size, 1], padding='valid'),\n                                          nn.BatchNorm2d(emb_size),\n                                          nn.GELU())\n\n        self.Fix_Position = tAPE(emb_size, dropout=config['dropout'], max_len=seq_len)\n\n        self.attention_layer = Attention_Rel_Scl(emb_size, num_heads, seq_len, config['dropout'])\n\n        self.LayerNorm = nn.LayerNorm(emb_size, eps=1e-5)\n        self.LayerNorm2 = nn.LayerNorm(emb_size, eps=1e-5)\n\n        self.FeedForward = nn.Sequential(\n            nn.Linear(emb_size, dim_ff),\n            nn.ReLU(),\n            nn.Dropout(config['dropout']),\n            nn.Linear(dim_ff, emb_size),\n            nn.Dropout(config['dropout']))\n\n        self.gap = nn.AdaptiveAvgPool1d(1)\n        self.flatten = nn.Flatten()\n        self.out = nn.Linear(emb_size, num_classes)\n        self.out_binary = nn.Sigmoid()\n\n\n\n    def forward(self, x_):\n        if torch.isnan(x_).any().item():\n            ipdb.set_trace(context = 5)\n        x = x_.squeeze()\n        x = self.spatial_convolution(x)\n        x = x.squeeze()\n        #ipdb.set_trace()\n        x = self.input_normalization(x)\n        #ipdb.set_trace()\n        if torch.isnan(x).any().item():\n            ipdb.set_trace(context = 5)\n        #ipdb.set_trace()\n        x = x.unsqueeze(1) #now it is batch_size, 1, feature_size, sequence_len where the 1 is how many channels for the conv2d in first embed\n        #ipdb.set_trace()\n        x_src = self.embed_layer(x)\n        #ipdb.set_trace()\n        x_src = self.embed_layer2(x_src)\n        if torch.isnan(x_src).any().item():\n            ipdb.set_trace(context = 5)\n        x_src = x_src.squeeze(2)\n        #ipdb.set_trace()\n        x_src = x_src.permute(0, 2, 1)\n        #ipdb.set_trace()\n        x_src_pos = self.Fix_Position(x_src)\n        #ipdb.set_trace()\n        att = x_src + self.attention_layer(x_src_pos)\n        #ipdb.set_trace()\n        att = self.LayerNorm(att)\n        #ipdb.set_trace()\n        out = att + self.FeedForward(att)\n        #ipdb.set_trace()\n        out = self.LayerNorm2(out)\n        #ipdb.set_trace()\n        out = out.permute(0, 2, 1)\n        #ipdb.set_trace()\n        out = self.gap(out)\n        #ipdb.set_trace()\n        out = self.flatten(out)\n        #ipdb.set_trace()\n        out = self.out(out)\n        #ipdb.set_trace()\n        out = self.out_binary(out)\n        #print(torch.isnan(out).any().item())\n        #ipdb.set_trace()\n        if torch.isnan(out).any().item():\n            ipdb.set_trace(context = 5)\n        return out","metadata":{"id":"4A7OofM_83iP","execution":{"iopub.status.busy":"2023-07-03T18:16:56.417101Z","iopub.execute_input":"2023-07-03T18:16:56.417492Z","iopub.status.idle":"2023-07-03T18:16:56.438102Z","shell.execute_reply.started":"2023-07-03T18:16:56.417463Z","shell.execute_reply":"2023-07-03T18:16:56.436816Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Dataset + Dataloader","metadata":{"id":"YYXjKLYF8o5G"}},{"cell_type":"code","source":"class TemporalDatasetFromNumpy(Dataset):\n    def __init__(self, numpy_array, sequence_length, radius, pin_memory, train_or_test):\n        self.numpy_array = numpy_array #shape (40, 40, 918, 29), lat, lon, time, var\n        self.sequence_length = sequence_length\n        self.pin_memory = pin_memory\n        \n        self.lat_size, self.lon_size, self.time_size, self.num_variables = self.numpy_array.shape\n\n        self.time_size -= (sequence_length) #num of timesteps with targets\n        self.numpy_array = self.numpy_array[:self.time_size]\n        # 40, 40, 854, 29\n        # 0 to 39\n        \n        self.train_or_test = train_or_test\n        \n        self.pos_indices = np.column_stack(np.where(self.numpy_array[1:39,1:39,self.sequence_length:, -1] == 1)) \n        # shape (number_of_occurences) by (lat_indices, lon_indices, time_indices)\n        self.neg_indices = np.column_stack(np.where(self.numpy_array[1:39,1:39,self.sequence_length:, -1] == 0))\n            \n        #ipdb.set_trace()\n        self.total_indices = None\n        \n        if (self.train_or_test): # True -> training; False -> eval\n             # 3/4 neg, 1/4 pos\n            total_row_values_to_delete = None\n            for index_arr in tqdm(self.pos_indices, desc = 'sampling'):\n                lat = index_arr[0]\n                lon = index_arr[1]\n                time = index_arr[2]\n                #radius = 0\n                lat_range = np.arange(lat-radius, lat+radius+1) #lat is 5: np.arange(3,8) 3, 4, 5, 6, 7\n                lon_range = np.arange(lon-radius, lon+radius+1)\n                diameter = radius*2+1\n                time_arr = np.array([time])\n\n                grid1, grid2, grid3 = np.meshgrid(lat_range, lon_range, time_arr, indexing='ij')\n                row_values_to_delete = np.vstack([grid1.ravel(), grid2.ravel(), grid3.ravel()]).T\n                if total_row_values_to_delete is None:\n                    total_row_values_to_delete = row_values_to_delete\n                else:\n                    total_row_values_to_delete = np.concatenate((total_row_values_to_delete, row_values_to_delete), axis=0)\n                \n            neg_indices_pd = pd.DataFrame(self.neg_indices)\n            \n            total_rows_to_delete_pd = pd.DataFrame(total_row_values_to_delete)\n            n_index = neg_indices_pd.set_index([0,1,2]).index\n            t_index = total_rows_to_delete_pd.set_index([0,1,2]).index\n            mask = ~n_index.isin(t_index)\n            result = neg_indices_pd.loc[mask]\n            self.neg_indices = result.to_numpy()\n            \n            neg_to_pos_ratio = 2\n            num_rows = len(self.pos_indices)*neg_to_pos_ratio\n            random_rows = np.random.choice(self.neg_indices.shape[0], size=num_rows, replace=False)\n            #ipdb.set_trace()\n            neg_indices_subset = self.neg_indices[random_rows, :]\n            #ipdb.set_trace()\n            \n            self.total_indices = np.concatenate((self.pos_indices, neg_indices_subset), axis=0)\n            #self.total_indices = np.concatenate((self.pos_indices, self.neg_indices), axis=0)\n            \n        else:\n            self.total_indices = np.concatenate((self.pos_indices, self.neg_indices), axis=0)\n        \n        np.random.shuffle(self.total_indices)\n        #ipdb.set_trace()\n            \n    def __len__(self): # num_samples * num_timesteps\n        return len(self.total_indices)\n\n    def __getitem__(self, index): # np array shape (40, 40, 918, 29), lat, lon, time, var\n        #total indices shape (num samples) by (lat_indices, lon_indices, time_indices)\n        lat_index = self.total_indices[index, 0]+1\n        lon_index = self.total_indices[index, 1]+1\n        time_index = self.total_indices[index, 2]\n\n        # ex timesteps 0 to 64: 65 timesteps in total, features takes 0 to 63, target is 64th timestep\n        target_np = self.numpy_array[lat_index, lon_index, time_index+sequence_length, -1] # only last variable gwis_ba\n        features_np = self.numpy_array[lat_index-1:lat_index+2, lon_index-1:lon_index+2, time_index:time_index+sequence_length, : ] # all variables\n        # lat, lon, time, var\n        \n        #target_np shape ()\n        #features_np shape (64,29) lat lon time features, wants features timestep lat lon \n        #ipdb.set_trace()\n        if self.pin_memory:\n            target_tensor = torch.from_numpy(np.asarray(target_np)).pin_memory()\n            features_tensor = torch.from_numpy(np.asarray(features_np)).pin_memory()\n        else:\n            target_tensor = torch.from_numpy(np.asarray(target_np))\n            features_tensor = torch.from_numpy(np.asarray(features_np))\n        \n        target_tensor = target_tensor.float()\n        features_tensor = features_tensor.float().permute(3, 2, 0, 1) #now features, time, lat, lon\n        if features_tensor.shape != torch.Size([29, 64, 3, 3]):\n            ipdb.set_trace(context=5)\n        #if (torch.isnan(features_tensor).any().item()):\n        #    ipdb.set_trace(context=5)\n        #if (torch.isnan(features_tensor).any().item()):\n        #    return\n        \n        return features_tensor, target_tensor\n\ndef temporal_dataloader(numpy_array, sequence_length, batch_size, radius, train_or_test, pin_memory=True, num_workers=0):\n    temporal_dataset = TemporalDatasetFromNumpy(numpy_array, sequence_length, radius, pin_memory, train_or_test)\n    dataloader = DataLoader(temporal_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    return dataloader\n","metadata":{"id":"Dbga3drn8sCE","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-03T17:48:04.468235Z","iopub.execute_input":"2023-07-03T17:48:04.468538Z","iopub.status.idle":"2023-07-03T17:48:04.494251Z","shell.execute_reply.started":"2023-07-03T17:48:04.468512Z","shell.execute_reply":"2023-07-03T17:48:04.493174Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Trainer + Evaluator","metadata":{"id":"zmt0TF_39e1Q"}},{"cell_type":"code","source":"# Define the training loop\ndef train(model, dataloader, optimizer, criterion, device, epoch_num): #each dataloader gives 1203*150 samples\n    model.train()\n    total_loss = 0.0\n    total_samples = 0.0\n\n    for batch_features, batch_target in tqdm(dataloader, desc = f'training epoch {epoch_num}'): #ndvi missing values\n        if torch.isnan(batch_features).any().item():\n            #Flatten:\n            shape = batch_features.shape\n            batch_features_reshaped = batch_features.reshape(shape[0],-1)\n            #Drop all rows containing any nan:\n            mask = ~torch.any(batch_features_reshaped.isnan(),dim=1)\n            batch_features_reshaped = batch_features_reshaped[mask]\n            #Reshape back:\n            #ipdb.set_trace()\n            batch_features = batch_features_reshaped.reshape(batch_features_reshaped.shape[0],*shape[1:])\n            batch_target = batch_target[mask]\n\n        batch_features = batch_features.to(device)\n        batch_target = batch_target.squeeze().to(device)\n        #ipdb.set_trace()\n        # Forward pass\n        outputs = model(batch_features).squeeze()\n        #print(outputs, batch_target)\n\n        if (torch.isnan(outputs).any().item()):\n            ipdb.set_trace(context=5)\n\n        loss = criterion(outputs, batch_target)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=4.0)\n        optimizer.step()\n        \n        num_samples = len(outputs)\n        total_loss+=loss.sum()\n        total_samples += num_samples\n        \n        #print(f'batch #{num_batches} end')\n    # retrieve: model.load_state_dict(torch.load(checkpoint_path))\n    return total_loss, total_samples\n\n\ndef evaluate_model(model, dataloader, criterion, device):\n    model.eval()  # Set the model to evaluation mode\n    total_f1 = 0.0\n    total_recall = 0.0\n    total_precision = 0.0\n    total_accuracy = 0.0\n    total_aucroc = 0.0\n    total_auprc = 0.0\n    total_loss = 0.0\n    total_loss_samples = 0.0\n    total_samples = 0.0 #because each batch is the same size\n\n    for inputs, targets in tqdm(dataloader, desc = 'evaluating'):\n        with torch.no_grad():\n            #ipdb.set_trace(context=5)\n\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            \n            if torch.isnan(inputs).any().item():\n                #Flatten:\n                shape = inputs.shape\n                inputs_reshaped = inputs.reshape(shape[0],-1)\n                #Drop all rows containing any nan:\n                mask = ~torch.any(inputs_reshaped.isnan(),dim=1)\n                inputs_reshaped = inputs_reshaped[mask]\n                #Reshape back:\n                #ipdb.set_trace()\n                inputs = inputs_reshaped.reshape(inputs_reshaped.shape[0],*shape[1:])\n                targets = targets[mask]\n            \n            #ipdb.set_trace(context=5)\n            # Forward pass\n            outputs = model(inputs).squeeze()\n            loss = criterion(outputs, targets)\n            \n            #ipdb.set_trace(context=5)\n            targets = targets.squeeze().cpu().numpy()\n            predicted = torch.round(outputs).cpu().numpy()\n\n            num_samples = len(targets)\n            \n            \n            total_loss+=loss.sum()\n            total_loss_samples += num_samples\n            \n            #ipdb.set_trace(context=5)\n            #true, pred\n            if (np.sum(targets) > 0):\n                #ipdb.set_trace()\n                total_f1 += f1_score(targets, predicted, pos_label=1) * num_samples\n                total_precision += precision_score(targets, predicted, pos_label=1) * num_samples\n                total_accuracy += accuracy_score(targets, predicted) * num_samples\n                total_recall += recall_score(targets, predicted, pos_label=1) * num_samples\n                total_aucroc += roc_auc_score(targets, predicted) * num_samples\n                total_auprc += average_precision_score(targets, predicted) * num_samples\n                total_samples += num_samples\n\n    #average_f1 = total_f1 / total_batches\n    #average_recall = total_recall / total_batches\n    #average_precision = total_precision / total_batches\n    #average_aucroc = total_aucroc / total_batches\n    #average_accuracy = total_accuracy / total_batches\n    return total_f1, total_recall, total_precision, total_auprc, total_aucroc, total_accuracy, total_samples, total_loss, total_loss_samples","metadata":{"id":"Azn6vrTy9iyd","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-03T17:48:04.497031Z","iopub.execute_input":"2023-07-03T17:48:04.497472Z","iopub.status.idle":"2023-07-03T17:48:04.518840Z","shell.execute_reply.started":"2023-07-03T17:48:04.497437Z","shell.execute_reply":"2023-07-03T17:48:04.517766Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# configging","metadata":{"id":"DeM35Ph--XMy"}},{"cell_type":"code","source":"feature_names = ['tp', 'rel_hum', 'ws10', 't2m_mean', 't2m_min', 't2m_max', 'swvl1', 'swvl2', 'swvl3', 'swvl4', 'lsm', 'drought_code_max',\n                 'drought_code_mean', 'fwi_max', 'fwi_mean', 'lst_day', 'lai', 'ndvi', 'pop_dens', 'lccs_class_0', 'lccs_class_1',\n                 'lccs_class_2', 'lccs_class_3', 'lccs_class_4', 'lccs_class_5', 'lccs_class_6', 'lccs_class_7', 'lccs_class_8', 'gwis_ba']\ntarget_name = ['gwis_ba']\nsequence_length = 64 # look back 512 days\nconfig = {\n    'emb_size' : 16,\n    'dim_ff' : 256,\n    'num_heads' : 8,\n    'lr' : 1e-5,\n    'dropout' : 0.01,\n    'seed' : 1234,\n    'Data_shape' : [4000, len(feature_names), sequence_length], #samples, features, time\n    'num_labels' : 1\n}\n\n# config needs 'Data_shape', 'emb_size', 'num_heads', 'dim_ff'\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n#num_epochs = 20\n","metadata":{"id":"--tschFC-btf","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-03T17:48:04.520156Z","iopub.execute_input":"2023-07-03T17:48:04.520909Z","iopub.status.idle":"2023-07-03T17:48:04.564976Z","shell.execute_reply.started":"2023-07-03T17:48:04.520872Z","shell.execute_reply":"2023-07-03T17:48:04.563875Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# RUN!!!","metadata":{"id":"3tJV3on_HTSa"}},{"cell_type":"markdown","source":"conv tran","metadata":{}},{"cell_type":"code","source":"ConvTranModel = SpatioTemporalConvTran(config, num_classes=config['num_labels'])\noptimizer = RAdam(ConvTranModel.parameters(), lr=config['lr'], weight_decay=0)\n#pos_weight = torch.tensor([0.5]).to(device)\n#criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\ncriterion = nn.CrossEntropyLoss()\n#criterion = get_loss_module()\nprint(sum(p.numel() for p in ConvTranModel.parameters()))\n\nConvTranModel.to(device)\nfor layer in ConvTranModel.modules():\n    if isinstance(layer, nn.Module):\n        layer.to(device)\n        \nnum_epochs = 50\ntrain_losses = []\nval_losses = []\nfor epoch in range(num_epochs):\n    \n    batch_size = 50\n    file_path = Path('/kaggle/input/california-spatial-temporal-fire-dataset/numpy_california_spatialtemporal_dataset.npy')\n    train_numpy_array = np.load(file_path)[:,:,:700,:]\n    train_dataloader = temporal_dataloader(train_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    loss, samples = train(ConvTranModel, train_dataloader, optimizer, criterion, device, epoch)\n    del train_numpy_array\n    del train_dataloader\n    #checkpoint_path = f'/kaggle/output/model_checkpoints/model_checkpoint_epoch_{epoch}.pt'\n    #torch.save(ConvTranModel.state_dict(), checkpoint_path)\n    train_losses.append(loss.item()/samples)\n    \n    batch_size = 50\n    val_numpy_array = np.load(file_path)[:,:,700:,:]\n    val_dataloader = temporal_dataloader(val_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    f1, recall, precision, auprc, aucroc, accuracy, samples, loss, loss_samples = evaluate_model(ConvTranModel, val_dataloader, criterion, device)\n    del val_numpy_array\n    del val_dataloader\n    \n    val_losses.append(loss.item()/loss_samples)\n    \n    print(f'epoch #{epoch}:')\n    print(f'train_loss: {train_losses[epoch]}; val_loss: {val_losses[epoch]}!')\n    print(f'f1: {f1/samples}')\n    print(f'recall: {recall/samples}')\n    print(f'precision: {precision/samples}')\n    print(f'auprc: {auprc/samples}')\n    print(f'aucroc: {aucroc/samples}')\n    print(f'accuracy: {accuracy/samples}')","metadata":{"id":"sNkNYzbWHZOQ","outputId":"3d2071f9-01a0-4e68-c6f2-91be8fd22f04","execution":{"iopub.status.busy":"2023-07-03T18:17:00.676909Z","iopub.execute_input":"2023-07-03T18:17:00.677355Z","iopub.status.idle":"2023-07-03T18:31:05.916321Z","shell.execute_reply.started":"2023-07-03T18:17:00.677318Z","shell.execute_reply":"2023-07-03T18:31:05.915324Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"175977\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22384.67it/s]\ntraining epoch 0: 100%|██████████| 359/359 [00:12<00:00, 28.69it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21999.05it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #0:\ntrain_loss: 1.2635136549823365; val_loss: 1.2555451758256728!\nf1: 0.5681158354363437\nrecall: 0.8551415361072077\nprecision: 0.43048161259820134\nauprc: 0.418618718880108\naucroc: 0.6445440432359371\naccuracy: 0.5760045489006823\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21686.76it/s]\ntraining epoch 1: 100%|██████████| 359/359 [00:12<00:00, 28.02it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23247.39it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #1:\ntrain_loss: 1.2483098550097218; val_loss: 1.2377528886923725!\nf1: 0.575626604039818\nrecall: 0.831594702474498\nprecision: 0.44543301167445476\nauprc: 0.4277454755885363\naucroc: 0.6609639677725482\naccuracy: 0.6041979010494752\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22700.09it/s]\ntraining epoch 2: 100%|██████████| 359/359 [00:12<00:00, 28.98it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22506.55it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #2:\ntrain_loss: 1.2398690371560188; val_loss: 1.2355026293903988!\nf1: 0.5883001539060846\nrecall: 0.7856930012805624\nprecision: 0.47725234744361206\nauprc: 0.4506771118632614\naucroc: 0.6805954620432385\naccuracy: 0.646229076546925\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22324.26it/s]\ntraining epoch 3: 100%|██████████| 359/359 [00:12<00:00, 28.35it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23973.27it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #3:\ntrain_loss: 1.2361938395078584; val_loss: 1.2272625835483115!\nf1: 0.6063994429763733\nrecall: 0.7952443775134173\nprecision: 0.4986151855822013\nauprc: 0.4688385757524032\naucroc: 0.700758968467051\naccuracy: 0.6671669793621013\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21070.08it/s]\ntraining epoch 4: 100%|██████████| 359/359 [00:12<00:00, 29.28it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23519.53it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #4:\ntrain_loss: 1.2327450223675416; val_loss: 1.2324574634747922!\nf1: 0.6102818720504608\nrecall: 0.7934705272005079\nprecision: 0.503905366392076\nauprc: 0.47148322858537134\naucroc: 0.7030693666801623\naccuracy: 0.6727719033232629\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21841.73it/s]\ntraining epoch 5: 100%|██████████| 359/359 [00:12<00:00, 28.70it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23364.47it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #5:\ntrain_loss: 1.2295788386395428; val_loss: 1.2252748462152516!\nf1: 0.6070142881025558\nrecall: 0.8096086539047237\nprecision: 0.49246131766763485\nauprc: 0.46544539628085435\naucroc: 0.6991884595258052\naccuracy: 0.6630353117956423\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22593.72it/s]\ntraining epoch 6: 100%|██████████| 359/359 [00:12<00:00, 29.22it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23404.08it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #6:\ntrain_loss: 1.225701089479211; val_loss: 1.2267858960477247!\nf1: 0.6252871341888645\nrecall: 0.8128463426868725\nprecision: 0.5164082276546865\nauprc: 0.4838948751951474\naucroc: 0.7168189096068408\naccuracy: 0.6841012084592145\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21071.20it/s]\ntraining epoch 7: 100%|██████████| 359/359 [00:12<00:00, 28.73it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24215.22it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #7:\ntrain_loss: 1.2189653153819318; val_loss: 1.2210558593015328!\nf1: 0.622965597012949\nrecall: 0.7915028229304941\nprecision: 0.5222026233633578\nauprc: 0.48611737813930334\naucroc: 0.715994965713975\naccuracy: 0.6898627045326312\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21251.00it/s]\ntraining epoch 8: 100%|██████████| 359/359 [00:12<00:00, 29.43it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22932.04it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #8:\ntrain_loss: 1.2155228606236337; val_loss: 1.2203734292483968!\nf1: 0.6323748188883695\nrecall: 0.7916998102539685\nprecision: 0.5365503633421578\nauprc: 0.4971334167795965\naucroc: 0.726085723786123\naccuracy: 0.7036967182195398\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21575.26it/s]\ntraining epoch 9: 100%|██████████| 359/359 [00:12<00:00, 28.83it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 15359.61it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #9:\ntrain_loss: 1.2181375865144217; val_loss: 1.2159249507584666!\nf1: 0.6342067127188137\nrecall: 0.77680578895679\nprecision: 0.5446942942327182\nauprc: 0.5010351532034171\naucroc: 0.7283681151020985\naccuracy: 0.7125117591721543\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21683.04it/s]\ntraining epoch 10: 100%|██████████| 359/359 [00:12<00:00, 29.19it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21747.98it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #10:\ntrain_loss: 1.2132192147299434; val_loss: 1.2142549564116984!\nf1: 0.6183684807582285\nrecall: 0.720175309682905\nprecision: 0.5530837527201212\nauprc: 0.49384875689356017\naucroc: 0.7168386294819071\naccuracy: 0.7155980502437196\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21338.81it/s]\ntraining epoch 11: 100%|██████████| 359/359 [00:12<00:00, 29.16it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23733.06it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #11:\ntrain_loss: 1.2085551688748255; val_loss: 1.2153953559436852!\nf1: 0.6319557130154632\nrecall: 0.7587781210109549\nprecision: 0.5505982441549373\nauprc: 0.5015194274869126\naucroc: 0.7236093663951976\naccuracy: 0.7123468426013195\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22149.40it/s]\ntraining epoch 12: 100%|██████████| 359/359 [00:12<00:00, 28.93it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22614.88it/s]\nevaluating: 100%|██████████| 116/116 [00:03<00:00, 38.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #12:\ntrain_loss: 1.2093127649914899; val_loss: 1.2143659378232556!\nf1: 0.6211614183755936\nrecall: 0.7156434541602509\nprecision: 0.5587537961774227\nauprc: 0.5003195782769198\naucroc: 0.7176828126038227\naccuracy: 0.7182621779198797\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21557.51it/s]\ntraining epoch 13: 100%|██████████| 359/359 [00:12<00:00, 29.10it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23241.85it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #13:\ntrain_loss: 1.208290717392627; val_loss: 1.2115438323142051!\nf1: 0.6364987181011544\nrecall: 0.7638488277671719\nprecision: 0.5553379377950021\nauprc: 0.5068712698023554\naucroc: 0.7311904147259992\naccuracy: 0.7194731890874883\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22078.98it/s]\ntraining epoch 14: 100%|██████████| 359/359 [00:12<00:00, 28.20it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22906.33it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 44.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #14:\ntrain_loss: 1.205715807506678; val_loss: 1.2135875522304613!\nf1: 0.631055836476955\nrecall: 0.7455308556966066\nprecision: 0.5569874660649794\nauprc: 0.5034236692847751\naucroc: 0.7260935132564852\naccuracy: 0.7192090395480226\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 20852.53it/s]\ntraining epoch 15: 100%|██████████| 359/359 [00:12<00:00, 28.85it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22989.31it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #15:\ntrain_loss: 1.2080972513338415; val_loss: 1.211781586644527!\nf1: 0.6247699085501066\nrecall: 0.7882494546039989\nprecision: 0.5281102621641875\nauprc: 0.4906133967554869\naucroc: 0.7212081352572579\naccuracy: 0.6967705595193391\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 20486.22it/s]\ntraining epoch 16: 100%|██████████| 359/359 [00:12<00:00, 28.03it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22036.80it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 44.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #16:\ntrain_loss: 1.2063427930567394; val_loss: 1.2072824393044619!\nf1: 0.632330100154224\nrecall: 0.7500424260047569\nprecision: 0.5563088052547207\nauprc: 0.5029394410871991\naucroc: 0.7271989068427294\naccuracy: 0.7208473940757405\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21477.47it/s]\ntraining epoch 17: 100%|██████████| 359/359 [00:12<00:00, 28.94it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23310.08it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #17:\ntrain_loss: 1.2017592720927759; val_loss: 1.2149118822674418!\nf1: 0.6352054938185898\nrecall: 0.7896070040742563\nprecision: 0.538528390913534\nauprc: 0.4975092896960599\naucroc: 0.7259024166574217\naccuracy: 0.7058044999054641\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22548.48it/s]\ntraining epoch 18: 100%|██████████| 359/359 [00:12<00:00, 28.43it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21942.38it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #18:\ntrain_loss: 1.2037935184973825; val_loss: 1.20797626907277!\nf1: 0.6311594159796872\nrecall: 0.7513661985003673\nprecision: 0.5560048942580953\nauprc: 0.503636477321204\naucroc: 0.7283471827324508\naccuracy: 0.7183098591549296\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21313.34it/s]\ntraining epoch 19: 100%|██████████| 359/359 [00:12<00:00, 29.10it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23498.56it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #19:\ntrain_loss: 1.202263869435479; val_loss: 1.211500830520676!\nf1: 0.6362358953870391\nrecall: 0.7676241118507482\nprecision: 0.5513106062837878\nauprc: 0.5044290571766818\naucroc: 0.7294356402750776\naccuracy: 0.7167673716012085\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22115.81it/s]\ntraining epoch 20: 100%|██████████| 359/359 [00:12<00:00, 28.43it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22295.68it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #20:\ntrain_loss: 1.199543697419972; val_loss: 1.2060564293970615!\nf1: 0.6327010064963551\nrecall: 0.7391963558203141\nprecision: 0.561784752780937\nauprc: 0.5057196679543633\naucroc: 0.7264549436732719\naccuracy: 0.7221179121291776\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21976.06it/s]\ntraining epoch 21: 100%|██████████| 359/359 [00:12<00:00, 28.94it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22442.25it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #21:\ntrain_loss: 1.1968833681651292; val_loss: 1.209102436208239!\nf1: 0.6459640484014058\nrecall: 0.7849913564660472\nprecision: 0.5558279144804023\nauprc: 0.5126249884390096\naucroc: 0.7356543597052723\naccuracy: 0.7200830502076255\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21687.34it/s]\ntraining epoch 22: 100%|██████████| 359/359 [00:12<00:00, 27.98it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21754.29it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #22:\ntrain_loss: 1.200303079323995; val_loss: 1.2100301405455958!\nf1: 0.6276236039500457\nrecall: 0.7178589431713593\nprecision: 0.568661359442343\nauprc: 0.5059396031073123\naucroc: 0.7247082775855985\naccuracy: 0.7261434217955957\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21450.25it/s]\ntraining epoch 23: 100%|██████████| 359/359 [00:12<00:00, 29.70it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23838.22it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 39.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #23:\ntrain_loss: 1.198085129638078; val_loss: 1.2128826309336187!\nf1: 0.6183984389229116\nrecall: 0.7158702572558696\nprecision: 0.5560633637501673\nauprc: 0.4962838351789082\naucroc: 0.7179875492122656\naccuracy: 0.7173503951825367\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 13678.32it/s]\ntraining epoch 24: 100%|██████████| 359/359 [00:12<00:00, 29.32it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22463.37it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #24:\ntrain_loss: 1.1962124274933188; val_loss: 1.2063522180789696!\nf1: 0.6409012582020277\nrecall: 0.7572296112760385\nprecision: 0.5672170698155016\nauprc: 0.5139850205222188\naucroc: 0.7347765708698764\naccuracy: 0.7278206818609908\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22110.80it/s]\ntraining epoch 25: 100%|██████████| 359/359 [00:12<00:00, 29.53it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 20327.91it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 40.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #25:\ntrain_loss: 1.1953610675188016; val_loss: 1.2097312120980632!\nf1: 0.6270352805291828\nrecall: 0.7318773369605169\nprecision: 0.5616833608016222\nauprc: 0.5046953092347979\naucroc: 0.7248456851999299\naccuracy: 0.7224520496427228\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21871.69it/s]\ntraining epoch 26: 100%|██████████| 359/359 [00:12<00:00, 29.37it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24079.15it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #26:\ntrain_loss: 1.1970012333525906; val_loss: 1.2092242600476033!\nf1: 0.6475330172420455\nrecall: 0.7333235934432454\nprecision: 0.5905253100773807\nauprc: 0.5287789165061376\naucroc: 0.7402894950331382\naccuracy: 0.7432739674118984\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21998.69it/s]\ntraining epoch 27: 100%|██████████| 359/359 [00:12<00:00, 28.05it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23397.38it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #27:\ntrain_loss: 1.191687414798546; val_loss: 1.2025045371917358!\nf1: 0.6505058212829783\nrecall: 0.7699124777644588\nprecision: 0.5728485405218893\nauprc: 0.5212020183902277\naucroc: 0.7428361900288081\naccuracy: 0.7336219879518072\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21025.07it/s]\ntraining epoch 28: 100%|██████████| 359/359 [00:12<00:00, 29.24it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22704.62it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #28:\ntrain_loss: 1.193497082449227; val_loss: 1.2044543684662836!\nf1: 0.650823136350565\nrecall: 0.766270768727554\nprecision: 0.5750746111901927\nauprc: 0.5215985789362461\naucroc: 0.741394904311009\naccuracy: 0.7330947447730269\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22040.35it/s]\ntraining epoch 29: 100%|██████████| 359/359 [00:12<00:00, 28.16it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22754.87it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #29:\ntrain_loss: 1.1938467361406602; val_loss: 1.214457968069752!\nf1: 0.625131568026972\nrecall: 0.6592972297157038\nprecision: 0.6077392951220889\nauprc: 0.520003992592259\naucroc: 0.7233456709783973\naccuracy: 0.7442740866931667\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22698.35it/s]\ntraining epoch 30: 100%|██████████| 359/359 [00:12<00:00, 29.54it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23287.00it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #30:\ntrain_loss: 1.1907066744131385; val_loss: 1.2053547718603286!\nf1: 0.6301723257367045\nrecall: 0.7024772315034966\nprecision: 0.585626204791691\nauprc: 0.5158997066723738\naucroc: 0.730276181264168\naccuracy: 0.7378403755868544\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21810.76it/s]\ntraining epoch 31: 100%|██████████| 359/359 [00:12<00:00, 28.00it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22438.95it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #31:\ntrain_loss: 1.193642799383466; val_loss: 1.20994211486678!\nf1: 0.6372542233176449\nrecall: 0.7187740454422636\nprecision: 0.5853242242972733\nauprc: 0.5186929697912739\naucroc: 0.7314203912451981\naccuracy: 0.7352607709750567\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21105.65it/s]\ntraining epoch 32: 100%|██████████| 359/359 [00:12<00:00, 29.23it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22941.21it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #32:\ntrain_loss: 1.1954805812012077; val_loss: 1.20436621682484!\nf1: 0.6483560384404053\nrecall: 0.732043698822368\nprecision: 0.5926983221085873\nauprc: 0.5263104441468511\naucroc: 0.7426140257714684\naccuracy: 0.7451017332328561\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 17889.30it/s]\ntraining epoch 33: 100%|██████████| 359/359 [00:12<00:00, 28.18it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23042.15it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #33:\ntrain_loss: 1.1889057824684157; val_loss: 1.2073642149856485!\nf1: 0.6252428221338892\nrecall: 0.637708318271419\nprecision: 0.6265454629116501\nauprc: 0.5240771195288444\naucroc: 0.7253901475114681\naccuracy: 0.7556935817805382\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21594.54it/s]\ntraining epoch 34: 100%|██████████| 359/359 [00:12<00:00, 29.64it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22675.54it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #34:\ntrain_loss: 1.1905802149681528; val_loss: 1.2049985880579936!\nf1: 0.6499478545407188\nrecall: 0.7619034658010901\nprecision: 0.5758330072384463\nauprc: 0.5225147885274644\naucroc: 0.7419018805472545\naccuracy: 0.7349943374858438\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21990.45it/s]\ntraining epoch 35: 100%|██████████| 359/359 [00:12<00:00, 28.46it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22863.99it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #35:\ntrain_loss: 1.1912785497812481; val_loss: 1.2049631974658983!\nf1: 0.6352407602464565\nrecall: 0.7113271318850335\nprecision: 0.5871792534035105\nauprc: 0.5158322180338878\naucroc: 0.7304892139051457\naccuracy: 0.7364063969896519\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22144.56it/s]\ntraining epoch 36: 100%|██████████| 359/359 [00:12<00:00, 29.62it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22783.58it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #36:\ntrain_loss: 1.1916054927351207; val_loss: 1.2050363538133597!\nf1: 0.6326309149273914\nrecall: 0.6790176530129132\nprecision: 0.6071361133571158\nauprc: 0.5227493012828689\naucroc: 0.7300255581486894\naccuracy: 0.7471264367816092\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 14802.34it/s]\ntraining epoch 37: 100%|██████████| 359/359 [00:12<00:00, 29.40it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 18738.80it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #37:\ntrain_loss: 1.18927111632619; val_loss: 1.206513893401465!\nf1: 0.646778175303765\nrecall: 0.7754038964714884\nprecision: 0.5651945040059339\nauprc: 0.5164035092407868\naucroc: 0.7402318447502529\naccuracy: 0.7266540642722117\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 17578.86it/s]\ntraining epoch 38: 100%|██████████| 359/359 [00:11<00:00, 30.04it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23556.51it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 39.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #38:\ntrain_loss: 1.1862746234780106; val_loss: 1.2113222092316946!\nf1: 0.6236572619568673\nrecall: 0.6741479753774836\nprecision: 0.5916414105469175\nauprc: 0.5115299870515929\naucroc: 0.7225524356863309\naccuracy: 0.7401396489903755\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 23259.03it/s]\ntraining epoch 39: 100%|██████████| 359/359 [00:11<00:00, 30.21it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22359.76it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #39:\ntrain_loss: 1.1891604058278569; val_loss: 1.2084174878669507!\nf1: 0.6444716728486029\nrecall: 0.7110308127559613\nprecision: 0.6016639069035306\nauprc: 0.5289392679015943\naucroc: 0.7392793301352444\naccuracy: 0.7515151515151515\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21778.78it/s]\ntraining epoch 40: 100%|██████████| 359/359 [00:12<00:00, 28.90it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 16088.09it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #40:\ntrain_loss: 1.190838059536851; val_loss: 1.2007690636469508!\nf1: 0.650046136593594\nrecall: 0.7271474911814059\nprecision: 0.5994862526917817\nauprc: 0.5293549985288717\naucroc: 0.7431200649832151\naccuracy: 0.748729531338227\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21626.45it/s]\ntraining epoch 41: 100%|██████████| 359/359 [00:12<00:00, 29.71it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23244.05it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #41:\ntrain_loss: 1.1898568920347388; val_loss: 1.2119922206412612!\nf1: 0.6083036426104477\nrecall: 0.6256286061522208\nprecision: 0.6060075561472579\nauprc: 0.509546381281773\naucroc: 0.7109573277287294\naccuracy: 0.7405731523378583\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22567.77it/s]\ntraining epoch 42: 100%|██████████| 359/359 [00:12<00:00, 29.07it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23352.80it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #42:\ntrain_loss: 1.188351413912013; val_loss: 1.2024261670161138!\nf1: 0.6489850778420302\nrecall: 0.7469644206463829\nprecision: 0.5845091925487355\nauprc: 0.5260391288140525\naucroc: 0.7427704244869889\naccuracy: 0.741424802110818\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22601.42it/s]\ntraining epoch 43: 100%|██████████| 359/359 [00:11<00:00, 30.20it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24165.75it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 50.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #43:\ntrain_loss: 1.1896099686550152; val_loss: 1.2073881774971622!\nf1: 0.6477455269811798\nrecall: 0.7369959725080117\nprecision: 0.5882744793046996\nauprc: 0.5247477034613957\naucroc: 0.7388990321619323\naccuracy: 0.7395005675368899\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22658.51it/s]\ntraining epoch 44: 100%|██████████| 359/359 [00:12<00:00, 29.23it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23598.90it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #44:\ntrain_loss: 1.1870320576162967; val_loss: 1.208220144773178!\nf1: 0.6387449672588936\nrecall: 0.7137301604168569\nprecision: 0.5870030474610093\nauprc: 0.520513178256425\naucroc: 0.7320011170932945\naccuracy: 0.7388595166163142\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22532.72it/s]\ntraining epoch 45: 100%|██████████| 359/359 [00:12<00:00, 29.88it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23630.19it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #45:\ntrain_loss: 1.1875539268229642; val_loss: 1.1972541543824!\nf1: 0.6603179834249331\nrecall: 0.7317111862540467\nprecision: 0.6136485856526516\nauprc: 0.5421560404283967\naucroc: 0.7513269386186443\naccuracy: 0.7573764330013155\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22398.26it/s]\ntraining epoch 46: 100%|██████████| 359/359 [00:12<00:00, 29.20it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24248.53it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 50.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #46:\ntrain_loss: 1.1849726564869867; val_loss: 1.2045797941547867!\nf1: 0.6477903362387255\nrecall: 0.7191830759072861\nprecision: 0.5997823576425568\nauprc: 0.5308784532559873\naucroc: 0.7414407157773226\naccuracy: 0.7483006042296072\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22539.13it/s]\ntraining epoch 47: 100%|██████████| 359/359 [00:11<00:00, 30.57it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23239.91it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 50.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #47:\ntrain_loss: 1.1876311029367057; val_loss: 1.2024088909279127!\nf1: 0.6443520182817144\nrecall: 0.7863311640307288\nprecision: 0.5529912493617332\nauprc: 0.5107767588347769\naucroc: 0.7367102703804758\naccuracy: 0.720308676830416\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 19637.83it/s]\ntraining epoch 48: 100%|██████████| 359/359 [00:12<00:00, 29.75it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22077.15it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 50.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #48:\ntrain_loss: 1.1843638846544715; val_loss: 1.2108878786716093!\nf1: 0.6335781199958186\nrecall: 0.8012330929938821\nprecision: 0.5323410902604959\nauprc: 0.49545008278673625\naucroc: 0.7253349548283738\naccuracy: 0.7000377786173027\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 23481.84it/s]\ntraining epoch 49: 100%|██████████| 359/359 [00:11<00:00, 30.58it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24465.27it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch #49:\ntrain_loss: 1.183026003137885; val_loss: 1.2049122104303858!\nf1: 0.6299549675287004\nrecall: 0.667299156739844\nprecision: 0.610977693881953\nauprc: 0.5224252076366593\naucroc: 0.7279834964097728\naccuracy: 0.7473189087488241\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(50,100):\n    batch_size = 50\n    file_path = Path('/kaggle/input/california-spatial-temporal-fire-dataset/numpy_california_spatialtemporal_dataset.npy')\n    train_numpy_array = np.load(file_path)[:,:,:700,:]\n    train_dataloader = temporal_dataloader(train_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    loss, samples = train(ConvTranModel, train_dataloader, optimizer, criterion, device, epoch)\n    del train_numpy_array\n    del train_dataloader\n    #checkpoint_path = f'/kaggle/output/model_checkpoints/model_checkpoint_epoch_{epoch}.pt'\n    #torch.save(ConvTranModel.state_dict(), checkpoint_path)\n    train_losses.append(loss.item()/samples)\n    \n    batch_size = 50\n    val_numpy_array = np.load(file_path)[:,:,700:,:]\n    val_dataloader = temporal_dataloader(val_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    f1, recall, precision, auprc, aucroc, accuracy, samples, loss, loss_samples = evaluate_model(ConvTranModel, val_dataloader, criterion, device)\n    del val_numpy_array\n    del val_dataloader\n    \n    val_losses.append(loss.item()/loss_samples)\n    \n    print(f'epoch #{epoch}:')\n    print(f'train_loss: {train_losses[epoch]}; val_loss: {val_losses[epoch]}!')\n    print(f'f1: {f1/samples}')\n    print(f'recall: {recall/samples}')\n    print(f'precision: {precision/samples}')\n    print(f'auprc: {auprc/samples}')\n    print(f'aucroc: {aucroc/samples}')\n    print(f'accuracy: {accuracy/samples}')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:31:34.630768Z","iopub.execute_input":"2023-07-03T18:31:34.631223Z","iopub.status.idle":"2023-07-03T18:45:39.183295Z","shell.execute_reply.started":"2023-07-03T18:31:34.631188Z","shell.execute_reply":"2023-07-03T18:45:39.182254Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22126.34it/s]\ntraining epoch 50: 100%|██████████| 359/359 [00:12<00:00, 29.80it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24544.24it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #50:\ntrain_loss: 1.1875452915779063; val_loss: 1.201696809576575!\nf1: 0.6576660242611729\nrecall: 0.7378983772102474\nprecision: 0.6039488707721599\nauprc: 0.5367384342194612\naucroc: 0.7498330170221945\naccuracy: 0.7542436816295738\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22703.59it/s]\ntraining epoch 51: 100%|██████████| 359/359 [00:11<00:00, 30.33it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23640.07it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #51:\ntrain_loss: 1.185729215766026; val_loss: 1.2020297336902626!\nf1: 0.6567992633461521\nrecall: 0.7771094295906396\nprecision: 0.5776217968503008\nauprc: 0.5282116289146264\naucroc: 0.7472117308094338\naccuracy: 0.7374386097468832\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22463.78it/s]\ntraining epoch 52: 100%|██████████| 359/359 [00:12<00:00, 29.17it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23658.11it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #52:\ntrain_loss: 1.18985887942208; val_loss: 1.1996854745913959!\nf1: 0.6367294949882878\nrecall: 0.6760837764889273\nprecision: 0.6143741735037773\nauprc: 0.5287864627580149\naucroc: 0.7347058951503529\naccuracy: 0.7548374976517002\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 23030.02it/s]\ntraining epoch 53: 100%|██████████| 359/359 [00:12<00:00, 29.85it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23266.51it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #53:\ntrain_loss: 1.1849657319008993; val_loss: 1.2013691380488034!\nf1: 0.6495893435650549\nrecall: 0.7807660280546871\nprecision: 0.566314857100892\nauprc: 0.5183559696311814\naucroc: 0.74106898575772\naccuracy: 0.727152817034106\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22476.07it/s]\ntraining epoch 54: 100%|██████████| 359/359 [00:12<00:00, 29.22it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23328.43it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 50.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #54:\ntrain_loss: 1.185327697568389; val_loss: 1.2000046739565668!\nf1: 0.659293022067401\nrecall: 0.7510162362121604\nprecision: 0.5987873836033374\nauprc: 0.5361695027152473\naucroc: 0.7500883573325167\naccuracy: 0.7497644620312794\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 23450.35it/s]\ntraining epoch 55: 100%|██████████| 359/359 [00:11<00:00, 30.17it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23532.32it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #55:\ntrain_loss: 1.1857685373942677; val_loss: 1.2025024253534191!\nf1: 0.6334466209914901\nrecall: 0.7062068688718276\nprecision: 0.5873011908258735\nauprc: 0.5156418549514739\naucroc: 0.7313327846475927\naccuracy: 0.7399962427202705\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22855.41it/s]\ntraining epoch 56: 100%|██████████| 359/359 [00:12<00:00, 28.79it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23198.40it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #56:\ntrain_loss: 1.1861961320129752; val_loss: 1.2014339536136491!\nf1: 0.6516352095797227\nrecall: 0.6971089522335804\nprecision: 0.6235725882536554\nauprc: 0.540184810347646\naucroc: 0.7434015390860167\naccuracy: 0.7581009796533534\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22089.82it/s]\ntraining epoch 57: 100%|██████████| 359/359 [00:12<00:00, 29.38it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22064.63it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #57:\ntrain_loss: 1.184306245058387; val_loss: 1.2029411547111741!\nf1: 0.6582647216304758\nrecall: 0.7653969843273454\nprecision: 0.5881993837573193\nauprc: 0.5318214572081084\naucroc: 0.7482910600719713\naccuracy: 0.7418560606060606\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21154.65it/s]\ntraining epoch 58: 100%|██████████| 359/359 [00:12<00:00, 28.23it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22375.65it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #58:\ntrain_loss: 1.183063352048708; val_loss: 1.2002661698016657!\nf1: 0.6480497746740388\nrecall: 0.7288233322519151\nprecision: 0.5977525820696723\nauprc: 0.5300465236299081\naucroc: 0.7443159364164224\naccuracy: 0.748541313758705\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22466.78it/s]\ntraining epoch 59: 100%|██████████| 359/359 [00:12<00:00, 29.51it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22731.92it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #59:\ntrain_loss: 1.184162451949374; val_loss: 1.1997222038312148!\nf1: 0.6535428132051294\nrecall: 0.7136940844919467\nprecision: 0.6145198919438543\nauprc: 0.5381627753296625\naucroc: 0.7451381867682604\naccuracy: 0.7551789077212806\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21930.68it/s]\ntraining epoch 60: 100%|██████████| 359/359 [00:12<00:00, 29.14it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23916.51it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #60:\ntrain_loss: 1.1801144798230732; val_loss: 1.2060786201584508!\nf1: 0.6123137290904127\nrecall: 0.625461539659696\nprecision: 0.6165122655730905\nauprc: 0.5168205999085733\naucroc: 0.7154977505214831\naccuracy: 0.7453521126760564\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22409.73it/s]\ntraining epoch 61: 100%|██████████| 359/359 [00:12<00:00, 29.28it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23041.23it/s]\nevaluating: 100%|██████████| 116/116 [00:03<00:00, 37.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #61:\ntrain_loss: 1.1837555698339315; val_loss: 1.2062644792357036!\nf1: 0.6429598294728797\nrecall: 0.7206923136264655\nprecision: 0.5920942251784359\nauprc: 0.5260919696518267\naucroc: 0.7364985670930565\naccuracy: 0.7420943003219087\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22046.19it/s]\ntraining epoch 62: 100%|██████████| 359/359 [00:12<00:00, 29.38it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22314.31it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #62:\ntrain_loss: 1.1848849780167954; val_loss: 1.200488539112599!\nf1: 0.6559852015357863\nrecall: 0.7207896053626737\nprecision: 0.614838940836114\nauprc: 0.5403976623624264\naucroc: 0.7469799756376772\naccuracy: 0.7548095058468502\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22397.66it/s]\ntraining epoch 63: 100%|██████████| 359/359 [00:12<00:00, 28.44it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 15327.57it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #63:\ntrain_loss: 1.184563898686451; val_loss: 1.200230524648136!\nf1: 0.6525482966589154\nrecall: 0.7153756583783178\nprecision: 0.6116238598286662\nauprc: 0.5354508551344298\naucroc: 0.7438068542145172\naccuracy: 0.7544718508755414\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21271.96it/s]\ntraining epoch 64: 100%|██████████| 359/359 [00:12<00:00, 29.19it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23055.21it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #64:\ntrain_loss: 1.1792351126446883; val_loss: 1.2073927181075537!\nf1: 0.6291214775412005\nrecall: 0.6734721162326026\nprecision: 0.6037943840483454\nauprc: 0.5203489804382085\naucroc: 0.7276856470324873\naccuracy: 0.7457563183704262\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22785.18it/s]\ntraining epoch 65: 100%|██████████| 359/359 [00:12<00:00, 28.38it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23192.21it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #65:\ntrain_loss: 1.1832985004802121; val_loss: 1.2048925965855388!\nf1: 0.645215346679432\nrecall: 0.7016000602448618\nprecision: 0.6095376815466029\nauprc: 0.5306079123488434\naucroc: 0.7388110274894083\naccuracy: 0.7517958412098299\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21919.56it/s]\ntraining epoch 66: 100%|██████████| 359/359 [00:12<00:00, 29.52it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23140.61it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #66:\ntrain_loss: 1.1834616488504348; val_loss: 1.2077123662911775!\nf1: 0.648007365032092\nrecall: 0.7297449745028078\nprecision: 0.5957335731393241\nauprc: 0.528242014066601\naucroc: 0.7419561809840496\naccuracy: 0.7451722832260508\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22371.96it/s]\ntraining epoch 67: 100%|██████████| 359/359 [00:12<00:00, 28.65it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 17101.62it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #67:\ntrain_loss: 1.1780142878487563; val_loss: 1.2139673169946608!\nf1: 0.6108081154631743\nrecall: 0.664696712982584\nprecision: 0.5776657239299674\nauprc: 0.502765861847375\naucroc: 0.7130146082659637\naccuracy: 0.7306747306747307\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22313.62it/s]\ntraining epoch 68: 100%|██████████| 359/359 [00:12<00:00, 29.31it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23027.79it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #68:\ntrain_loss: 1.1798796630622574; val_loss: 1.1998659831582272!\nf1: 0.6276020312027104\nrecall: 0.7019219828755634\nprecision: 0.5796510837945013\nauprc: 0.5115127916553948\naucroc: 0.7283132450705062\naccuracy: 0.736989891426432\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 19183.80it/s]\ntraining epoch 69: 100%|██████████| 359/359 [00:12<00:00, 29.15it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24032.66it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #69:\ntrain_loss: 1.1842544655091043; val_loss: 1.2137982849786264!\nf1: 0.5870670939882084\nrecall: 0.5940327651868145\nprecision: 0.5959165476466014\nauprc: 0.4947348007470409\naucroc: 0.6978029077576032\naccuracy: 0.7331830139045472\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22904.04it/s]\ntraining epoch 70: 100%|██████████| 359/359 [00:12<00:00, 29.36it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23301.89it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #70:\ntrain_loss: 1.1792066869992717; val_loss: 1.2063425965306458!\nf1: 0.6110893177186045\nrecall: 0.641938349721659\nprecision: 0.5975348223051268\nauprc: 0.5076263854287528\naucroc: 0.7132710112597638\naccuracy: 0.7373756335648582\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22425.40it/s]\ntraining epoch 71: 100%|██████████| 359/359 [00:12<00:00, 27.97it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24192.92it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #71:\ntrain_loss: 1.1788200761021164; val_loss: 1.203948524633743!\nf1: 0.6465092704763221\nrecall: 0.7001424465770593\nprecision: 0.6143531421636534\nauprc: 0.5338338921312021\naucroc: 0.7420210816922954\naccuracy: 0.7546313799621929\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22018.58it/s]\ntraining epoch 72: 100%|██████████| 359/359 [00:12<00:00, 29.05it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22053.80it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #72:\ntrain_loss: 1.1815601596205263; val_loss: 1.216355894270637!\nf1: 0.5818431870786238\nrecall: 0.5773416260594609\nprecision: 0.6100839802527402\nauprc: 0.5021871573382919\naucroc: 0.6980408925096223\naccuracy: 0.7367131549189597\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22667.93it/s]\ntraining epoch 73: 100%|██████████| 359/359 [00:12<00:00, 28.54it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24302.43it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #73:\ntrain_loss: 1.178543127802351; val_loss: 1.2023434743944026!\nf1: 0.6412283602207647\nrecall: 0.745354118138109\nprecision: 0.5750981830865305\nauprc: 0.5153593127281558\naucroc: 0.7352953425465458\naccuracy: 0.7324553151458137\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22853.66it/s]\ntraining epoch 74: 100%|██████████| 359/359 [00:12<00:00, 29.43it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22615.20it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 44.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #74:\ntrain_loss: 1.1831125091257528; val_loss: 1.2019298726372956!\nf1: 0.6325931720018652\nrecall: 0.710777216423678\nprecision: 0.5847585565676972\nauprc: 0.5157146928898292\naucroc: 0.7320105583743215\naccuracy: 0.7381982320857626\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 15767.75it/s]\ntraining epoch 75: 100%|██████████| 359/359 [00:12<00:00, 29.01it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21704.98it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #75:\ntrain_loss: 1.1794422906660385; val_loss: 1.2125375487913845!\nf1: 0.6059445459706724\nrecall: 0.6774991600198363\nprecision: 0.5639578033887803\nauprc: 0.4936674486156621\naucroc: 0.7088259627206963\naccuracy: 0.7172686230248307\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21048.75it/s]\ntraining epoch 76: 100%|██████████| 359/359 [00:12<00:00, 28.64it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 15974.94it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 39.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #76:\ntrain_loss: 1.1775964223732873; val_loss: 1.2141827704099717!\nf1: 0.6128075473491378\nrecall: 0.6479656113765196\nprecision: 0.5943781437974067\nauprc: 0.5113628656085377\naucroc: 0.7135132960268957\naccuracy: 0.7353497164461248\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 20818.74it/s]\ntraining epoch 77: 100%|██████████| 359/359 [00:12<00:00, 28.76it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23358.74it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #77:\ntrain_loss: 1.17772431039709; val_loss: 1.2040916388313887!\nf1: 0.6306843257489643\nrecall: 0.6644595563592102\nprecision: 0.6096758418762972\nauprc: 0.5216688650888477\naucroc: 0.7252710825610739\naccuracy: 0.7468949943545352\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22548.01it/s]\ntraining epoch 78: 100%|██████████| 359/359 [00:12<00:00, 28.32it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22537.77it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #78:\ntrain_loss: 1.1797631914659001; val_loss: 1.2008842359515661!\nf1: 0.6313279122712114\nrecall: 0.6748881210507526\nprecision: 0.6041515709044237\nauprc: 0.5213673629411483\naucroc: 0.7304254555357114\naccuracy: 0.7507501875468867\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21603.35it/s]\ntraining epoch 79: 100%|██████████| 359/359 [00:12<00:00, 28.82it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23320.02it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #79:\ntrain_loss: 1.1801565253387616; val_loss: 1.2031111278515993!\nf1: 0.6327180407734786\nrecall: 0.6896586858265379\nprecision: 0.5973581638358498\nauprc: 0.5198309360412599\naucroc: 0.7304663956721018\naccuracy: 0.7444967074317969\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21764.58it/s]\ntraining epoch 80: 100%|██████████| 359/359 [00:12<00:00, 27.82it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22276.22it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #80:\ntrain_loss: 1.1798892362377653; val_loss: 1.2041657155690386!\nf1: 0.6367686775780974\nrecall: 0.7085506190092645\nprecision: 0.5907453733743521\nauprc: 0.5210084426705702\naucroc: 0.7333498211032762\naccuracy: 0.7417530631479736\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22559.77it/s]\ntraining epoch 81: 100%|██████████| 359/359 [00:12<00:00, 29.52it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23306.72it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #81:\ntrain_loss: 1.1762672199296031; val_loss: 1.2055997272801837!\nf1: 0.60932503658035\nrecall: 0.6345192221103757\nprecision: 0.5979779410767312\nauprc: 0.5062571817282912\naucroc: 0.7133649368677715\naccuracy: 0.7420322459692539\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21990.33it/s]\ntraining epoch 82: 100%|██████████| 359/359 [00:12<00:00, 28.19it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22436.09it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #82:\ntrain_loss: 1.1771498830305145; val_loss: 1.2013668928554593!\nf1: 0.6414746995915199\nrecall: 0.6615693093552167\nprecision: 0.638411583361872\nauprc: 0.5403031148612204\naucroc: 0.7392698559379168\naccuracy: 0.7648500848576277\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22483.69it/s]\ntraining epoch 83: 100%|██████████| 359/359 [00:12<00:00, 29.76it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24270.20it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #83:\ntrain_loss: 1.1778534434012387; val_loss: 1.1993335479409415!\nf1: 0.6461512325296984\nrecall: 0.7146698098983464\nprecision: 0.5996458013483721\nauprc: 0.527056241400107\naucroc: 0.7398080374145858\naccuracy: 0.7483555722608533\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21700.54it/s]\ntraining epoch 84: 100%|██████████| 359/359 [00:12<00:00, 28.20it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 20569.83it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #84:\ntrain_loss: 1.1810390596455973; val_loss: 1.2012426098962237!\nf1: 0.6204582165891717\nrecall: 0.6498928576002464\nprecision: 0.611706311252981\nauprc: 0.5165803316472282\naucroc: 0.7231763432400815\naccuracy: 0.7488755622188905\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22632.78it/s]\ntraining epoch 85: 100%|██████████| 359/359 [00:12<00:00, 29.34it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21642.62it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #85:\ntrain_loss: 1.1823643615603678; val_loss: 1.2228821171815634!\nf1: 0.6016243486800906\nrecall: 0.632270606539469\nprecision: 0.5863628979494993\nauprc: 0.501613811080174\naucroc: 0.7044561813202395\naccuracy: 0.7298632218844985\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 23099.10it/s]\ntraining epoch 86: 100%|██████████| 359/359 [00:12<00:00, 28.25it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23039.39it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #86:\ntrain_loss: 1.1798136613496746; val_loss: 1.211494549367223!\nf1: 0.6154031028575723\nrecall: 0.6603049691248211\nprecision: 0.5893715370699192\nauprc: 0.5072626449517497\naucroc: 0.7159774913605935\naccuracy: 0.7337858220211161\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22171.53it/s]\ntraining epoch 87: 100%|██████████| 359/359 [00:12<00:00, 29.48it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 19592.43it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #87:\ntrain_loss: 1.1772123476026357; val_loss: 1.213671543712307!\nf1: 0.6065551994729084\nrecall: 0.6611468856486395\nprecision: 0.5755399656284761\nauprc: 0.4960321695368046\naucroc: 0.7084989081762516\naccuracy: 0.7237090086694309\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 16460.40it/s]\ntraining epoch 88: 100%|██████████| 359/359 [00:11<00:00, 29.93it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23767.36it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #88:\ntrain_loss: 1.1816963606632187; val_loss: 1.2032865394082897!\nf1: 0.62487406795221\nrecall: 0.6894118531880518\nprecision: 0.5810332582462926\nauprc: 0.5083000567240394\naucroc: 0.7224066636654981\naccuracy: 0.7355588897224306\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 20201.31it/s]\ntraining epoch 89: 100%|██████████| 359/359 [00:12<00:00, 29.35it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23641.93it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 39.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #89:\ntrain_loss: 1.1781014171555813; val_loss: 1.2082028297987908!\nf1: 0.6292168766076606\nrecall: 0.6628547817379862\nprecision: 0.6114977646518737\nauprc: 0.5253358039946852\naucroc: 0.7261876248872329\naccuracy: 0.748535802002645\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22954.36it/s]\ntraining epoch 90: 100%|██████████| 359/359 [00:12<00:00, 29.49it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22290.03it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #90:\ntrain_loss: 1.1791318573220804; val_loss: 1.2042903400388785!\nf1: 0.6374252927271565\nrecall: 0.6997399286922378\nprecision: 0.5957688751807754\nauprc: 0.5237884166835816\naucroc: 0.732558318925983\naccuracy: 0.7436380772855796\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22518.51it/s]\ntraining epoch 91: 100%|██████████| 359/359 [00:12<00:00, 29.18it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23606.41it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #91:\ntrain_loss: 1.1791047347390353; val_loss: 1.19738941590514!\nf1: 0.6474280850277394\nrecall: 0.7389818677283029\nprecision: 0.5831498959252852\nauprc: 0.5232215073240616\naucroc: 0.7393440290550225\naccuracy: 0.7414019921067468\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21867.18it/s]\ntraining epoch 92: 100%|██████████| 359/359 [00:12<00:00, 29.64it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23631.30it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #92:\ntrain_loss: 1.17787569220471; val_loss: 1.205768893420002!\nf1: 0.6256876210809966\nrecall: 0.7092447818483024\nprecision: 0.5695219585430368\nauprc: 0.5056323982576525\naucroc: 0.7221033019437615\naccuracy: 0.7269823374671176\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21752.07it/s]\ntraining epoch 93: 100%|██████████| 359/359 [00:12<00:00, 27.67it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22293.71it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #93:\ntrain_loss: 1.1781103002082194; val_loss: 1.2035461807034356!\nf1: 0.6572888618485029\nrecall: 0.7298217040758099\nprecision: 0.6102897412731324\nauprc: 0.5399144733302002\naucroc: 0.7488257378228168\naccuracy: 0.7539276925989021\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21252.91it/s]\ntraining epoch 94: 100%|██████████| 359/359 [00:12<00:00, 29.36it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21751.89it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #94:\ntrain_loss: 1.1777208552811342; val_loss: 1.2030538018873471!\nf1: 0.6370090120940607\nrecall: 0.6722003797057422\nprecision: 0.6193480517376249\nauprc: 0.5292652843725595\naucroc: 0.7331372785228564\naccuracy: 0.7525870178739417\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22484.28it/s]\ntraining epoch 95: 100%|██████████| 359/359 [00:12<00:00, 28.38it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21847.46it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 45.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #95:\ntrain_loss: 1.1786650906105571; val_loss: 1.1957124290976275!\nf1: 0.663505045084544\nrecall: 0.769896827908939\nprecision: 0.5909751022416752\nauprc: 0.5344930103658503\naucroc: 0.7523254015828348\naccuracy: 0.7478817548484278\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 21382.07it/s]\ntraining epoch 96: 100%|██████████| 359/359 [00:11<00:00, 29.97it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 24118.42it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 49.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #96:\ntrain_loss: 1.178145846298039; val_loss: 1.2169073734626301!\nf1: 0.5992805141109253\nrecall: 0.585094899239464\nprecision: 0.6293121375578079\nauprc: 0.5130044324902983\naucroc: 0.7054157766827621\naccuracy: 0.7464522232734153\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22484.68it/s]\ntraining epoch 97: 100%|██████████| 359/359 [00:12<00:00, 28.80it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 21721.88it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 46.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #97:\ntrain_loss: 1.1761865281873176; val_loss: 1.2032098382908405!\nf1: 0.6482054624746226\nrecall: 0.7345508266177847\nprecision: 0.5906860158632204\nauprc: 0.5258777610872881\naucroc: 0.74121394627944\naccuracy: 0.7440982058545798\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22653.16it/s]\ntraining epoch 98: 100%|██████████| 359/359 [00:12<00:00, 29.53it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 22307.73it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 47.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #98:\ntrain_loss: 1.178945483597457; val_loss: 1.2116215908689196!\nf1: 0.6067507446192059\nrecall: 0.6320792797114173\nprecision: 0.5977691344604796\nauprc: 0.5076899105122866\naucroc: 0.7115794742021194\naccuracy: 0.7383107088989442\n","output_type":"stream"},{"name":"stderr","text":"sampling: 100%|██████████| 5974/5974 [00:00<00:00, 22058.59it/s]\ntraining epoch 99: 100%|██████████| 359/359 [00:12<00:00, 28.78it/s]\nsampling: 100%|██████████| 1929/1929 [00:00<00:00, 23291.36it/s]\nevaluating: 100%|██████████| 116/116 [00:02<00:00, 48.23it/s]","output_type":"stream"},{"name":"stdout","text":"epoch #99:\ntrain_loss: 1.177560463359451; val_loss: 1.2035602531526444!\nf1: 0.6306645118473377\nrecall: 0.6628419307003045\nprecision: 0.6192378251503993\nauprc: 0.5242500698848755\naucroc: 0.7291973798440163\naccuracy: 0.7507999247129682\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(100,150):\n    batch_size = 50\n    file_path = Path('/kaggle/input/california-spatial-temporal-fire-dataset/numpy_california_spatialtemporal_dataset.npy')\n    train_numpy_array = np.load(file_path)[:,:,:700,:]\n    train_dataloader = temporal_dataloader(train_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    loss, samples = train(ConvTranModel, train_dataloader, optimizer, criterion, device, epoch)\n    del train_numpy_array\n    del train_dataloader\n    #checkpoint_path = f'/kaggle/output/model_checkpoints/model_checkpoint_epoch_{epoch}.pt'\n    #torch.save(ConvTranModel.state_dict(), checkpoint_path)\n    train_losses.append(loss.item()/samples)\n    \n    batch_size = 50\n    val_numpy_array = np.load(file_path)[:,:,700:,:]\n    val_dataloader = temporal_dataloader(val_numpy_array, sequence_length, batch_size, radius = 0, train_or_test = True, pin_memory = False, num_workers=0)\n    f1, recall, precision, auprc, aucroc, accuracy, samples, loss, loss_samples = evaluate_model(ConvTranModel, val_dataloader, criterion, device)\n    del val_numpy_array\n    del val_dataloader\n    \n    val_losses.append(loss.item()/loss_samples)\n    \n    print(f'epoch #{epoch}:')\n    print(f'train_loss: {train_losses[epoch]}; val_loss: {val_losses[epoch]}!')\n    print(f'f1: {f1/samples}')\n    print(f'recall: {recall/samples}')\n    print(f'precision: {precision/samples}')\n    print(f'auprc: {auprc/samples}')\n    print(f'aucroc: {aucroc/samples}')\n    print(f'accuracy: {accuracy/samples}')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T17:49:12.837079Z","iopub.status.idle":"2023-07-03T17:49:12.837573Z","shell.execute_reply.started":"2023-07-03T17:49:12.837318Z","shell.execute_reply":"2023-07-03T17:49:12.837341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses, label = 'train')\nplt.plot(val_losses, label = 'val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:31:11.736797Z","iopub.execute_input":"2023-07-03T18:31:11.737711Z","iopub.status.idle":"2023-07-03T18:31:12.039061Z","shell.execute_reply.started":"2023-07-03T18:31:11.737675Z","shell.execute_reply":"2023-07-03T18:31:12.037836Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8m0lEQVR4nO3dd3iTVfvA8W+STjoptNBC2XuVsqeAggpYBQciKKC4UUHe14GoP/VVcKGiOHAiKrXIRhFEZe9V9qaFQls23TvP74/TpBQ6kjZN0nJ/ritX0icnT04esbl7zn3uo9M0TUMIIYQQwonpHd0BIYQQQojSSMAihBBCCKcnAYsQQgghnJ4ELEIIIYRwehKwCCGEEMLpScAihBBCCKcnAYsQQgghnJ4ELEIIIYRwei6O7oCtGI1G4uPj8fHxQafTObo7QgghhLCApmmkpKQQEhKCXl/8OEqVCVji4+MJDQ11dDeEEEIIUQZxcXHUrVu32OerTMDi4+MDqA/s6+vr4N4IIYQQwhLJycmEhoaav8eLU2UCFtM0kK+vrwQsQgghRCVTWjqHJN0KIYQQwulJwCKEEEIIpycBixBCCCGcXpXJYRFCCCEqgqZp5ObmkpeX5+iuVEoGgwEXF5dylxyRgEUIIYQoRnZ2NgkJCaSnpzu6K5VatWrVCA4Oxs3NrcznkIBFCCGEKILRaCQmJgaDwUBISAhubm5SmNRKmqaRnZ3N+fPniYmJoWnTpiUWhyuJBCxCCCFEEbKzszEajYSGhlKtWjVHd6fS8vT0xNXVlZMnT5KdnY2Hh0eZziNJt0IIIUQJyjoiIArY4hrKfwUhhBBCOD0JWIQQQgjh9CRgEUIIIUSxGjRowCeffOLobkjSrRBCCFHV9O3bl/bt29sk0Ni2bRteXl7l71Q5yQhLKX7cGMuL83YTeyHN0V0RQgghbMJUDM8SgYGBTrFKSgKWUizYdYa5209zMCHZ0V0RQgjhYJqmkZ6d65CbpmkW9XHMmDGsWbOG6dOno9Pp0Ol0zJo1C51Ox4oVK+jUqRPu7u6sW7eO48ePc9ddd1GrVi28vb3p3Lkzf//9d6HzXTslpNPp+Pbbbxk6dCjVqlWjadOmLFmyxJaXuUgyJVSKhjWqsTvuCjEXZYRFCCFudBk5ebR6fYVD3vvAW7dRza30r+3p06dz5MgR2rRpw1tvvQXA/v37AXjxxRf58MMPadSoEf7+/pw+fZpBgwbx9ttv4+HhwY8//khERASHDx+mXr16xb7Hm2++yfvvv88HH3zAZ599xsiRIzl58iQBAQG2+bBFkBGWUjSoqebtZEpICCFEZeDn54ebmxvVqlWjdu3a1K5dG4PBAMBbb73FgAEDaNy4MTVq1CAsLIwnnniCtm3b0rRpU95++20aNWpU6ojJmDFjeOCBB2jSpAlTpkwhLS2NrVu3VujnkhGWUjQ0Byyyj4QQQtzoPF0NHHjrNoe9d3l16tSp0M9paWm8+eab/P7778THx5Obm0tGRganTp0q8Tzt2rUzP/by8sLHx4dz586Vu38lkYClFA1qqIBFpoSEEELodDqLpmWc1bWrfV544QVWrFjBhx9+SJMmTfD09OTee+8lOzu7xPO4uroW+lmn02E0Gm3e36tV3qtuJ6YpofMpWaRm5eLtLpdMCCGEc3NzcyMvL6/UduvWrWPMmDEMHToUgNTUVGJjYyu4d2UjOSyl8PN0JcBLbYcteSxCCCEqgwYNGrBlyxZiY2O5cOFCsaMfTZo0YcGCBURHR7N7925GjBhR4SMlZSUBiwUa1FDrz2NlWkgIIUQl8N///heDwUCrVq0IDAwsNifl448/pnr16vTo0YOIiAhuu+02OnToYOfeWkbmNyzQoKYXO09dIea8BCxCCCGcX7Nmzdi0aVOhY2PGjLmuXYMGDfj3338LHRs3blyhn6+dIiqqHsyVK1fK1E9ryAiLBRrVlMRbIYQQwpEkYLGA1GIRQgghHMvqgGXt2rVEREQQEhKCTqdj0aJFJbZfsGABAwYMIDAwEF9fX7p3786KFddXCbxy5Qrjxo0jODgYDw8PWrZsybJly6ztXoUwLW2OvSi1WIQQQghHsDpgSUtLIywsjBkzZljUfu3atQwYMIBly5axY8cO+vXrR0REBLt27TK3yc7OZsCAAcTGxjJv3jwOHz7MN998Q506daztXoUwjbBcSssmKSPHwb0RQgghbjxWJ90OHDiQgQMHWtz+2q2tp0yZwuLFi1m6dCnh4eEAfP/991y6dImNGzeai9HUr1/f2q5VGG93FwJ93DmfkkXshTTCQv0d3SUhhBDihmL3HBaj0UhKSkqhDZKWLFlC9+7dGTduHLVq1aJNmzZMmTKlxKI3WVlZJCcnF7pVpIbmaSHJYxFCCCHsze4By7Rp00hLS2PYsGHmYydOnGDevHnk5eWxbNkyXn31VaZNm8Y777xT7HmmTp2Kn5+f+RYaGlqh/W5QU9ViiZHEWyGEEMLu7BqwREZG8sYbbxAVFUVQUJD5uNFoJCgoiK+//pqOHTsyfPhwJk+ezJdfflnsuSZNmkRSUpL5FhcXV6F9N+WxSMAihBBC2J/dApaoqCjGjh3L3Llz6d+/f6HngoODadasmXn7a4CWLVuSmJhY7AZM7u7u+Pr6FrpVpEaytFkIIcQNokGDBtfloDqaXQKWyMhIxowZw5w5cxg8ePB1z/fs2ZNjx44V2r/gyJEjBAcH4+bmZo8ulurqEZaiqvwJIYQQouJYHbCkpqYSHR1NdHQ0ADExMURHR5v3KZg0aRKjRo0yt4+MjGTUqFFMmzaNbt26kZiYSGJiIklJSeY2Tz31FBcvXmT8+PEcOXKEP/74gylTplxXHtiR6geogCU5M5fL6bK0WQghhLAnqwOW7du3Ex4ebl6SPHHiRMLDw3n99dcBSEhIKLTJ0syZM8nNzTUXhTPdxo8fb24TGhrKX3/9xbZt22jXrh3PPfcc48eP5+WXXy7v57MZTzcDwX4egOSxCCGEcF4zZ86kTp061+26fOeddzJ69GiOHz/OXXfdRa1atfD29qZz5878/fffDuqt5ayuw9K3b98Sp0RmzZpV6OfVq1dbdN7u3buzefNma7tjVw1qeJGQlEnshTQ61q/u6O4IIYSwN02DHAdVPXetBjpdqc3uu+8+nnvuOVatWsUtt9wCwOXLl1mxYgVLly4lNTWVQYMG8fbbb+Ph4cGPP/5IREQEhw8fpl69ehX9KcpMdmu2QoOaXmw6cVFqsQghxI0qJx2mhDjmvV+JBzevUpsFBARw++23M2fOHHPA8ttvvxEQEMAtt9yCwWAgLCzM3P7tt99m4cKFLFmyhGeeeabCul9esvmhFRpKLRYhhBCVwMiRI5k/fz5ZWVkA/PLLLwwfPhyDwUBaWhovvvgirVq1wt/fH29vbw4dOlQoncMZyQiLFRpItVshhLixuVZTIx2Oem8LRUREYDQa+eOPP+jcuTPr1q3jo48+AuCFF15gxYoVfPjhhzRp0gRPT0/uvffeYsuIOAsJWKzQ0LS0+bxa2qyzYC5RCCFEFaLTWTQt42ienp7cfffd/PLLLxw7doxmzZrRsWNHANatW8eYMWMYOnQooFb/xsbGOrC3lpGAxQr1alRDp4O07DzOp2YR5OPh6C4JIYQQRRo5ciQRERHs37+fBx980Hy8SZMmLFiwgIiICHQ6Ha+99tp1K4qckeSwWMHdxUAdf08AYi84KEtcCCGEsMDNN99MQEAAhw8fZsSIEebjH3/8MdWrV6dHjx5ERERw22230aFDBwf21DIywmKlhjW9OH05g9gLaXRpGFD6C4QQQggHMBgMxMdfn2/ToEED/v3330LHri3U6oxTRDLCYiVT4m2MJN4KIYQQdiMBi5UayCaIQgghhN1JwGIlqcUihBBC2J8ELKWJ3wX75kPaBaBgSujkxXSMRtm1WQghhLAHCVhKs/gZmPeIClyA0IBqGPQ6MnLyOJuS6eDOCSGEEDcGCVhK45+/EdQVVbLY1aAntLpa2izTQkIIUfWVtOGvsIwtrqEELKW5JmCBqxNvpRaLEEJUVa6urgCkp8vv+vIyXUPTNS0LqcNSmqIClhpewHnZU0gIIaowg8GAv78/586dA6BatWqyJYuVNE0jPT2dc+fO4e/vj8FgKPO5JGApjV+our8qYDHvKSRTQkIIUaXVrl0bwBy0iLLx9/c3X8uykoClNKYRlqQ48yGpxSKEEDcGnU5HcHAwQUFB5OTkOLo7lZKrq2u5RlZMJGApjSlgST0LORng6klD09LmS2pps14vQ4RCCFGVGQwGm3zpirKTpNvSeFYHN2/1OOk0ACH+HrgadGTnGolPynBg54QQQogbgwQspdHprkq8PQmAi0FPaICqeCsrhYQQQoiKJwGLJcwBS0Eei2laKOZCqiN6JIQQQtxQJGCxRBFLmwtWCskIixBCCFHRJGCxRBFLm80rhaQWixBCCFHhJGCxRBFLmxvK0mYhhBDCbiRgsUQJ5flPXUonN8/oiF4JIYQQNwwJWCzhX1/dpyRAbhYAwb4euLvoyTVqnLkiS5uFEEKIiiQBiyWqBYCrWsZsqsWi1+uoX0MdkxL9QgghRMWSgMUShWqxXLsJouSxCCGEEBVNAhZLlbi0WQIWIYQQoiJJwGKpEpY2x1yUWixCCCFERZKAxVIljLDIlJAQQghRsawOWNauXUtERAQhISHodDoWLVpUYvsFCxYwYMAAAgMD8fX1pXv37qxYsaJQm1mzZqHT6a67ZWZmWtu9ilNCLZbTl9PJzpWlzUIIIURFsTpgSUtLIywsjBkzZljUfu3atQwYMIBly5axY8cO+vXrR0REBLt27SrUztfXl4SEhEI3Dw8Pa7tXcUxLm68aYQnycaeamwGjBnGXZVpICCGEqCgu1r5g4MCBDBw40OL2n3zySaGfp0yZwuLFi1m6dCnh4eHm4zqdjtq1a1vbHfvxz89hSY6H3GxwcUOn01G/hhcHE5KJvZBG40Bvx/ZRCCGEqKLsnsNiNBpJSUkhICCg0PHU1FTq169P3bp1ueOOO64bgblWVlYWycnJhW4VyisQXDwADZLPmA83rCm1WIQQQoiKZveAZdq0aaSlpTFs2DDzsRYtWjBr1iyWLFlCZGQkHh4e9OzZk6NHjxZ7nqlTp+Ln52e+hYaGVmzHS6vFIpsgCiGEEBXGrgFLZGQkb7zxBlFRUQQFBZmPd+vWjQcffJCwsDB69+7N3LlzadasGZ999lmx55o0aRJJSUnmW1xcXLFtbaakpc0ywiKEEEJUGKtzWMoqKiqKsWPH8ttvv9G/f/8S2+r1ejp37lziCIu7uzvu7u627mbJSlzaLEm3QgghREWxywhLZGQkY8aMYc6cOQwePLjU9pqmER0dTXBwsB16Z4USljbHJ2WQmZPniF4JIYQQVZ7VIyypqakcO3bM/HNMTAzR0dEEBARQr149Jk2axJkzZ5g9ezaggpVRo0Yxffp0unXrRmJiIgCenp74+fkB8Oabb9KtWzeaNm1KcnIyn376KdHR0Xz++ee2+Iy2U8QISw0vN3zcXUjJyuXUpXSa1fJxUOeEEEKIqsvqEZbt27cTHh5uXpI8ceJEwsPDef311wFISEjg1KmCL/SZM2eSm5vLuHHjCA4ONt/Gjx9vbnPlyhUef/xxWrZsya233sqZM2dYu3YtXbp0Ke/ns60iAhadTid5LEIIIUQF02mapjm6E7aQnJyMn58fSUlJ+Pr6VsybpCTCtOag08Or58DgCsCzkbtYujuelwe24Mk+jSvmvYUQQogqyNLvb9lLyBpeQWBwB82oCsjlaxWsLvD22MuO6pkQQghRpUnAYg29vqDi7VXTQj0a1wBgy4mL5ObJnkJCCCGErUnAYq0iarG0qeOHr4dKvN17JslBHRNCCCGqLglYrFXE0maDXke3RmqUZePxi47olRBCCFGlScBirSJWCgH0bFITgI3HL9i7R0IIIUSVJwGLtYoNWNQIy/bYy1JATgghhLAxCVisZQ5YThY63DjQmyAfd7Jyjew8KauFhBBCCFuSgMVapoAlOR7ycs2HdTqdebXQBpkWEkIIIWxKAhZredcGvSsYcyElodBTPfLzWDYck8RbIYQQwpYkYLGWXg9+ddXjYhJv95y+QnJmjr17JoQQQlRZErCURRFLmwHq+HvSoEY1jBpsPXHJAR0TQgghqiYJWMqimJVCcNW0kOSxCCGEEDYjAUtZ+NdX99esFALo2Ti/HovksQghhBA2IwFLWRSxn5BJ9/yVQofPpnA+JcuevRJCCCGqLAlYysI8JRR33VMBXm7m3Zul6q0QQghhGxKwlIU56fY0GK+vamuqx7JJ9hUSQgghbEIClrLwCQa9CxhzICXxuqd7SuKtEEIIYVMSsJSF3gC+ddTjIvJYujQMwEWvI+5SBnGX0u3cOSGEEKLqkYClrIqpxQLg5e5C+1B/ADYck1EWIYQQorwkYCmrEpY2w9X1WCSPRQghhCgvCVjKqoSlzQA9zYm3F9A0zV69EkIIIaokCVjKqoSlzQDh9arj4arnQmo2R86m2rFjQgghRNUjAUtZlVCeH8DNRU/nBgGA5LEIIYQQ5SUBS1n55U8JJcWB0VhkE9PyZikgJ4QQQpSPBCxl5VsHdAbIy4bUs0U2Me0rtOXEJXLzig5qhBBCCFE6CVjKyuBSUIuliKXNAK1CfPHzdCUlK5c9Z5Ls2DkhhBCiapGApTxKyWMx6HV0b6RWC22UPBYhhBCizCRgKQ/z0uaia7EA9GyiApYNx6QeixBCCFFWErCURykjLFBQQG7Hqctk5ly/UaIQQgghSicBS3mUUosFoFFNL2r7epCda2THyct26pgQQghRtVgdsKxdu5aIiAhCQkLQ6XQsWrSoxPYLFixgwIABBAYG4uvrS/fu3VmxYkWx7X/99Vd0Oh1Dhgyxtmv2Z8EIi06no0dj07SQ5LEIIYQQZWF1wJKWlkZYWBgzZsywqP3atWsZMGAAy5YtY8eOHfTr14+IiAh27dp1XduTJ0/y3//+l969e1vbLce4uhZLCeX3ZV8hIYQQonxcrH3BwIEDGThwoMXtP/nkk0I/T5kyhcWLF7N06VLCw8PNx/Py8hg5ciRvvvkm69at48qVK9Z2zf5864BOD7mZkHYevIOKbGZKvN17+gpJGTn4ebras5dCCCFEpWf3HBaj0UhKSgoBAQGFjr/11lsEBgYyduxYe3ep7FzcwCdEPS5hWijYz5NGNb0warDlhIyyCCGEENaye8Aybdo00tLSGDZsmPnYhg0b+O677/jmm28sPk9WVhbJycmFbg5hwdJmgB75oyzrJY9FCCGEsJpdA5bIyEjeeOMNoqKiCApS0ycpKSk8+OCDfPPNN9SsWdPic02dOhU/Pz/zLTQ0tKK6XTILEm8Bbm6hPu/c7XGcuZJR0b0SQgghqhS7BSxRUVGMHTuWuXPn0r9/f/Px48ePExsbS0REBC4uLri4uDB79myWLFmCi4sLx48fL/J8kyZNIikpyXyLiyt+aXGFsmBpM0C/5kF0aRhAZo6Rt38/YIeOCSGEEFWH1Um3ZREZGckjjzxCZGQkgwcPLvRcixYt2Lt3b6Fjr776KikpKUyfPr3YkRN3d3fc3d0rrM8Ws3CERafT8dZdrRn86Xr+3JfImiPn6dMs0A4dFEIIISo/qwOW1NRUjh07Zv45JiaG6OhoAgICqFevHpMmTeLMmTPMnj0bUMHKqFGjmD59Ot26dSMxMREAT09P/Pz88PDwoE2bNoXew9/fH+C6407JtLS5lIAFoEVtX0Z3b8D3G2J4Y8l+lk/ojbuLoYI7KIQQQlR+Vk8Jbd++nfDwcPOS5IkTJxIeHs7rr78OQEJCAqdOFXx5z5w5k9zcXMaNG0dwcLD5Nn78eBt9BAczjbCUUovFZMKApgT6uBNzIY1v18VUcOeEEEKIqkGnaRZ8y1YCycnJ+Pn5kZSUhK+vr/3eODcL3q4FaPDCcfAqPXF44a7TPB+1Gw9XPf/8py91/D0rvp9CCCGEE7L0+1v2EiovF3fwqa0el7K02WRI+zp0aSAJuEIIIYSlJGCxBQsTb010Oh1vDWmNQa8zJ+AKIYQQongSsNiCKWA5vd3il5gScAHeWLKfrNy8CuiYEEIIUTVIwGILjfqp+00zYNt3Fr9MEnCFEEIIy0jAYgvtR0CP59TjPybCjh8tepmvhyuvDGoBwGf/HpUKuEIIIUQxJGCxBZ0OBrwF3Z5WPy8dD9FzLHrp1Qm4/1sqCbhCCCFEUSRgsRWdDm6bAl0eBzRY9DTs+c2ClxUk4C7fLwm4QgghRFEkYLElnQ4Gvg8dHwY0WPg47FtQ6sskAVcIIYQomQQstqbTweCPIPxB0Iww/1E4sKTUl0kCrhBCCFE8CVgqgl4PEZ9Cu+Gg5cG8h+HwnyW+5NoE3JMX0+zRUyGEEKJSkIClougNMOQLaHMvGHNh7ig4urLElwxpX4cejWuQmWPklYV7qSK7JgghhBDlJgFLRdIbYOhMaHUX5GXDryMhZl2xzXU6HVOGtsXdRc+GYxeZv/OMHTsrhBBCOC8JWCqawQXu+Q5a3AF5WfDPWyU2b1DTiwn9mwHwv98PcD4lyx69FEIIIZyaBCz2YHCF299Vj8/sgMykEps/2rshrYJ9ScrI4S3ZHFEIIYSQgMVu/EOhRhOVhBu7vsSmrgY9793TDr0Olu6O599DZ+3USSGEEMI5ScBiT436qvvjq0pt2rauH2N7NQTg1YX7SM3KrcCOCSGEEM5NAhZ7Mm2SeGK1Rc2fH9CM0ABP4pMy+XDF4YrrlxBCCOHkJGCxpwa9QKeHi0ch6XSpzau5uTBlaFsAftwUy85Tlyu6h0IIIYRTkoDFnjz9oU5H9djCUZbeTQO5u0MdNA0mzd9Ldq6xwronhBBCOCsJWOzNijwWk9cGt6KGlxuHz6Ywc83xiumXEEII4cQkYLG3q/NYjJaNllT3cuP1iFYAfPbvMY6dS62gzgkhhBDOSQIWe6vbGVyrQfoFOLff4pfdGRZC3+aBZOcZeWXBXoxGKdsvhBDixiEBi725uEH9nuqxhXksoMr2vz2kDdXcDGyNvUTktlMV0z8hhBDCCUnA4giNrVvebFK3ejVeuK05AO8uO0T8lQwbd0wIIYRwThKwOIIp8TZ2A+Rat1fQqG71+dp/Nh8Z3+XFqO0yNSSEEOKGIAGLIwS1Aq8gyM2AuK1WvdQQv4NbM5czwLATw8l1fL8hpoI6KYQQQjgPCVgcQacrGGU5YfnyZgC2zjQ/HKDfzvsrDnM4McV2fRNCCCGckAQsjlKWPJaUs7B/kfnHwe7R5OTmMiEqmqzcPJt2TwghhHAmErA4immEJX4XZFhYcn/HLDDmQEg4uHpRPe8iPaqd5mBCMh+vPFpRPRVCCCEcTgIWR/ENgZrNQTNCzLrS2+dmw/bv1ePuz0CTmwF4q/lJAGauPc7WmEsV1VshhBDCoSRgcSRr8lgOLYXURPCuBS3vhOaDAWh8aR3DOtVF02Di3GhSMnMqrr9CCCGEg1gdsKxdu5aIiAhCQkLQ6XQsWrSoxPYLFixgwIABBAYG4uvrS/fu3VmxYsV1bTp16oS/vz9eXl60b9+en376ydquVT7W5LFs+Vrdd3xYFZ9rdpva+fnsPv6vtzehAZ6cvpzBW0sPVFh3hRBCCEexOmBJS0sjLCyMGTNmWNR+7dq1DBgwgGXLlrFjxw769etHREQEu3btMrcJCAhg8uTJbNq0iT179vDwww/z8MMPXxfYVDn1e4LOAJdOwOWTxbdL2A1xm0HvAp0eVseqBUC97gB4xazko2Ht0evgtx2nWb4v0Q6dF0IIIexHp2lamSuP6XQ6Fi5cyJAhQ6x6XevWrbn//vt5/fXXi23ToUMHBg8ezP/+9z+LzpmcnIyfnx9JSUn4+vpa1R+H+u42FYxEfAodRxfdZvE42PUztLkH7v2+4PjGGfDXZGh4E4xeyvvLD/HF6uMEeLmxfEJvgnw87PMZhBBCiDKy9Pvb7jksRqORlJQUAgICinxe0zT++ecfDh8+zE033VTsebKyskhOTi50q5RKy2NJvwR756nHXZ4o/Fzzgeo+dgNkXGZC/2a0CvblUlo2L83bQzliUSGEEMKp2D1gmTZtGmlpaQwbNqzQ8aSkJLy9vXFzc2Pw4MF89tlnDBgwoNjzTJ06FT8/P/MtNDS0orteMcx5LGvAaLz++Z2zITcTgsMgtEvh52o0hsAWoOXB0b9xc9HzyfD2uLnoWXX4PHO2ygaJQgghqga7BiyRkZG88cYbREVFERQUVOg5Hx8foqOj2bZtG++88w4TJ05k9erVxZ5r0qRJJCUlmW9xcXEV3PsKUqcjuHlDxiU4u7fwc8Y82PadetzlcVUh91qmUZbDfwDQrJYPL93eAoC3fz/IyYtpFdVzIYQQwm7sFrBERUUxduxY5s6dS//+/a/viF5PkyZNaN++Pf/5z3+49957mTp1arHnc3d3x9fXt9CtUjK4QoNe6vHxa6aFjiyHpFPgGaDyV4qSv7yZo3+rWi3Awz0a0KNxDTJy8piy7GAFdVwIIYSwH7sELJGRkYwZM4Y5c+YwePBgi16jaRpZWdbtZFxpNSpmefOW/H2DOowCV8+iX1uno9pIMTsFYlUBOr1ex5t3tsag17Fi/1k2Hr9QMf0WQggh7MTqgCU1NZXo6Giio6MBiImJITo6mlOnVL7EpEmTGDVqlLl9ZGQko0aNYtq0aXTr1o3ExEQSExNJSkoyt5k6dSorV67kxIkTHDp0iI8++ojZs2fz4IMPlvPjVRKmxNtTmyAnUz0+dwhi1qhaK53HFv9avR6a364eH/7TfLhpLR9Gdq0HqKmhPKMk4AohhKi8rA5Ytm/fTnh4OOHh4QBMnDiR8PBw8xLlhIQEc/ACMHPmTHJzcxk3bhzBwcHm2/jx481t0tLSePrpp2ndujU9evRg3rx5/Pzzzzz66KPl/XyVQ2Bz8AlWybVxm9Wxbd+o++aDwL9eya83TQsd/hOuWhk0oX8zfDxcOJCQzLwdlTTHRwghhKCcdVicSaWtw2Ky8EnYHQk9J0DviTCtJeSkwagl0KhPya/NyYD3G0FOOjyxVq0oyvftuhO8/cdBanq7s/qFvni7u1Ts5xBCCCGs4LR1WEQxrs5jiY5UwUpgS1UUrjSuntBYbYbIoWWFnhrVvQENa3pxITWLL1Yds22fhRBCCDuRgMVZmEZREnbDpvxtD7o8VvRS5qJcs7zZxM1FzyuDWgLw7foY4i6l26K3QgghhF1JwOIsfGpDUCtAg6Q4cPeDdvdb/vpmtwM6SNwLVwrnq/RvGUSPxjXIzjXy7vJDNu22EEIIYQ8SsDgT02ohgPCR4O5t+Wu9akJoV/X4qtVCoPZ8eu2OVuh18MeeBLbHXip/X4UQQgg7koDFmZjyWAA6l2GFVItB6v7wsuueahnsy/2d1fYFb/1+AKMscxZCCFGJSMDiTBr1hTb3Qt9X1D5B1jItb45dD5lJ1z09cUBzvN1d2HM6iYW7zqjS/5djy9VlIYQQwh4kYHEmLm5w73fQ96Wyvb5mE6jRFIw5cOzv654O9HFnXL8mAEQu/5e8bwfA9DDY8nV5ei2EEEJUOAlYqhrTtNCh66eFAB7uUY/nfFbxU/Z/MMTvUAc3f170TtFCCCGEk5CApappnh+wHF0JeTmFn0s6jUfkPUzM+QZPXTYbtTYY3bzVtNDJDXbvqhBCCGEpCViqmrqdoVpNyEoqCEI0DaLnwBfdIWYNmosn3/k8zcisl9ns2Ve12fWzw7oshBBClEYClqpGb8ivyYKaFko9D1EPwqKnICsZ6nZG9+R6utz/Muj0vH+ui2p7YHGRibpCCCGEM5CApSoy5bHsmw9fdINDv4PeFW5+DR5eDjWb0LauH0Pb1yFaa0yiWwPIzVDthRBCCCckAUtV1KgvuHhA+gV1C2oFj/0LN/0XDAWbHz7QtR6g46fs/P2Kdv7kkO4KIYQQpZGApSpy84I294BOr3Z/fnw1BLe7rlnHetUJ8nHn18zuGHUuEL8Tzu63e3eFEEKI0kjAUlXdOQNePAED3gQX9yKb6PU6bmtdm4v4sd+nhzooybdCCCGckAQsVZVeD57VS202sG1tAL5OyQ9Ydv8KudkV2TMhhBDCahKw3OC6NAighpcbyzJak+VZCzIuFbkXkRBCCOFIErDc4FwMem5tXZs8DGz0vlUdlGkhIYQQTkYCFsGg/GmhTy7m12Q5/g8knXFgj4QQQojCJGARdGtUAz9PV3an1yA5qAtoRtg9x9HdEkIIIcwkYBG4GvTc2qoWACs9rpoWkg0RhRBCOAkJWAQAg9oGA/BJfEs0Nx/ZEFEIIYRTkYBFANCjSQ18PFyIS9VxvsEd6uAuqXwrhBDCOUjAIgBwdzHQv6WaFlqqv0UdlA0RhRBCOAkJWITZwDZqtdC3J6qjBbaE3EzZEFEIIYRTkIBFmN3ULBAvNwMJyVmcaXiPOigbIgohhHACErAIMw9XAzfnTwvNy+kJetkQUQghhHOQgEUUMih/WmjeoUy05gPVQal8K4QQwsEkYBGF9GkeiIerntOXMzhZL39aSDZEFEII4WASsIhCqrm50K95EAC/XWkKPsFqQ8QDix3cMyGEEDcyCVjEdQbmF5H7Y995tLAR6uCCR+GrXrBqKiTsBk1zYA+FEELcaKwOWNauXUtERAQhISHodDoWLVpUYvsFCxYwYMAAAgMD8fX1pXv37qxYsaJQm2+++YbevXtTvXp1qlevTv/+/dm6dau1XRM2cnOLINxc9MReTOdI49HQZADo9JC4F9a8CzNvgk/awrIX4cRqyMtxdJeFEEJUcVYHLGlpaYSFhTFjxgyL2q9du5YBAwawbNkyduzYQb9+/YiIiGDXrl3mNqtXr+aBBx5g1apVbNq0iXr16nHrrbdy5ozsGOwI3u4u3NQ0EIA/jmXBg/Pgv8fgri+gxR3g4glJcbB1Jsy+Cz5oDPMfhfhdpZxZCCGEKBudppV9bF+n07Fw4UKGDBli1etat27N/fffz+uvv17k83l5eVSvXp0ZM2YwatQoi86ZnJyMn58fSUlJ+Pr6WtUfcb0FO08zce5umgZ5s3Jin8JP5mSokZVDv8Ph5ZB+QR1384EJe6BagN37K4QQonKy9Pvb7jksRqORlJQUAgKK/1JLT08nJyenxDZZWVkkJycXugnbuaVlLVwNOo6eS+Xo2ZTCT7p6QvOBcNfn8N8j8MgKCGwB2Smw+QvHdFgIIUSVZveAZdq0aaSlpTFs2LBi27z88svUqVOH/v37F9tm6tSp+Pn5mW+hoaEV0d0blp+nK72a1ATgz32JxTfUG6BeN+j3ivp5y0zIuGyHHgohhLiR2DVgiYyM5I033iAqKoqgoKAi27z//vtERkayYMECPDw8ij3XpEmTSEpKMt/i4uIqqts3rIFt1GqhZXsTSm/cIgKCWkFWMmz+soJ7JoQQ4kZjt4AlKiqKsWPHMnfu3GJHTj788EOmTJnCX3/9Rbt27Uo8n7u7O76+voVuwrYGtKqFQa/jUGIKMRfSSm6s10OfF9XjzV9BxpUK758QQogbh10ClsjISMaMGcOcOXMYPHhwkW0++OAD/ve//7F8+XI6depkj26JUlT3cqNH4xqAhaMsLe+CwJaQlaSmhoQQQggbsTpgSU1NJTo6mujoaABiYmKIjo7m1KlTgJqquXplT2RkJKNGjWLatGl069aNxMREEhMTSUpKMrd5//33efXVV/n+++9p0KCBuU1qamo5P54or0H5ReR+3BhLUkYp9Vb0eujzgnq8+XPITCq5vRBCCGEhqwOW7du3Ex4eTnh4OAATJ04kPDzcvEQ5ISHBHLwAzJw5k9zcXMaNG0dwcLD5Nn78eHObL774guzsbO69995CbT788MPyfj5RTkPD69CwphfnUrJ4b/mh0l/QagjUbK6ClS1fV3j/hBBC3BjKVYfFmUgdloqz+cRFhn+9GYCox7vRtVGNkl+wdx7MHwse/jBhL3io/x5ZuXkYjeDpZqjgHgshhKgsnLYOi6h8ujWqwQNd1LLxSQv2kpmTV/ILWg+FGk0h8wpsVaMsl9KyGTR9Hb3e+5cLqVkV3GMhhBBVjQQswiIvD2xJoI87Jy6kMePfYyU31hvgpvxclk0zyEq7wpM/7eD4+TQupmXz8+aTFd9hIYQQVYoELMIifp6u/O+u1gB8teY4BxNKqSzc5h4IaAwZl1n54xS2xl7CoNcB8NOmk6WP0gghhBBXkYBFWOz2NsHc1roWuUaNlxfsJc9YQvqTwcU8ytL97Bx89Fl8O6oTdfw9uZiWzcJdsrGlEEIIy0nAIqzy1l1t8HF3YXfcFX7cGFti2xX6XsQYa1FDl8KsNnvo1yKIh3s2AOC79TEYSwp4hBBCiKtIwCKsUsvXg0mDWgLw4V+HibuUXmS7vaeTGP/bPj7PGwJAx9M/QXYa93cOxcfdhWPnUllz5Ly9ui2EEKKSk4BFWG1451C6NAwgPTuPyYv2ce3K+MSkTB6dvY3MHCMXGg1Fq94A0i/A9u/x8XBleP6Ko2/WnXBA74UQQlRGErAIq+n1Oqbe3RY3Fz1rj5xncXS8+bn07Fwenb2Ns8lZNA3y5tORndD1/q96csN0yE5nTM+GGPQ6Nh6/yP54qYYrhBCidBKwiDJpHOjN+FuaAvDm0v1cTM3CaNSYGLWbfWeSCfBy4/sxnfH1cIWw4eBfD9LOw44fqOPvaS75/926GEd+DCGEEJWEBCyizB6/qREtavtwOT2Ht/84yId/HWb5/kTcDHq+fqgjoQHVVEODK/T+j3q8/mO4cJTHejcEYMnueBKTMh30CYQQQlQWErCIMnM16Hn3nnbodLBw1xm+WH0cgPfubUunBgGFG4eNUHVZ0s7D131pd/lvujQMINeoMauU1UZCCCGEBCyiXNqH+vNwj4bmn5/p14Sh4XWvb+jiBg8vg/q9IDsV5o9lWrXZuJPNnC0nScvKtewNNQ0O/g6/T4T9C8EoBeiEEOJGIJsfinJLy8pl/K/R1K3uyet3tEKfX9G2SHm5sHoqrFM7cR/RN2ZsxjOMvaMfY3o2LP51mgbH/oFVb0P8roLjAY2gx3MQ9gC4etjoEwkhhLAXS7+/JWARjnF0JSx4HDIukaxV4z3353jr5ZfN5fsLiV0P/74Npzapn129oOUdcGSF2mARwLsWdHsKOj0CHn52+xg2l5MJq96BFndAva6O7o0QQlQ4CViE80s6Td7cMRjObAMgpukYGg7/UCXpApzergKVE6vUzwZ36PIY9JwA3oGQlQo7Z8OmGZCcX+rf3VcFLd2eBp9a9v9M5bXla/jzBajZDJ7Z5ujeCCFEhZOARVQOeTls+3Y8nRN+UT/X7Qx9J8HWb+DIn+qY3gU6jIab/gu+IdefIzcb9s2D9Z/AhcPqmMEd2j8AfV4G32C7fBSb+PleOLZSPR63FQKbO7Y/wnLbv4dzh+D2qWrHciGERSRgEZXGuZRM/u+9D3jP8AW+uqtK/ev0Kjelz4tQvUHpJzIa4chytXT69FZ1rEYTeGwVeFSCfxPZ6fB+Q8jNX+Z982sqSBPOLzcbptaFvCwYtRga9XV0j4SoNCz9/pZVQsLhgnw88A67k8HZ73DSPX9EofXdaoRhyBeWBSsAej20GARj/4KH/wTfunDxGCx6SiXtOrvY9QXBCsCh3x3XF2GdxL0qWAE4ucmxfRGiipKARTiFsb0bEqfV4ubk1zjz2D647weo2bRsJ9PpoH4PGDYbDG7qi3/D9LJ3Li8HstPK/npLHf1L3be4A9Cp1VBX4ir+fUX5mUb0AE5ucFw/hKjCJGARTqFFbV96N61Jnqbn253Jtjlp3Y4w8D31+J834cQa689x8TjM6AwfNlf1XyqKpsHRFepx+5FQr7t6fOiPintPYTuntxV+nJvtuL4IUUVJwCKcxmO9GwEwd1scSRk5tjlpx4dVAKAZYd4jkHTa8tcm7oXvb4fLMZCdAlEjYc0HFTO9dOEoXDmlRoQa3qSWbYNMC1UWVwcsuZmFawUJIWxCAhbhNHo3rUmL2j6kZefx8+aTtjmpTgeDp0HttpB+AeaOhtys0l93ajP8MBjSzkGttmqpNKjCdfMetv0UkWllUP2e4O6dPy2Eml5Iu2Db93Kk9EtqOXpVknJWBZvoCpJtZVpICJuTgEU4DZ1Ox+M3qVGWHzbEkJljo7L7rp4w7Cfw8Icz22H5pJLbH10Js4dAVpKamhnzO9zxMURMB72r2hLg+9ttm19iyl9pequ6r14fardTI0OH/7Td+zhS4j74pB18c7Na0VVVmEZXglpCs9vV45MbHdcfIaooCViEU4kIC6GOvycXUrOZu92GAUFAQ7jnW0AH27+D6DlFt9s7DyKHQ26GCh4eXACe/uq5jmNg9BKoVhMS98A3/WyzIiQrFWLz/yI3BSwALSPUfVWYFspMgrkPqam1C4chbrOje2Q7poTbup1VsjeoETrZ50oIm5KARTgVV4OeJ/qoUZaZa06Qk2fDv8SbDoC+L6vHvz8PCXsKP7/tW5j/KBhzoe19MHwOuFUr3KZ+D3h8lZpiSjsPP0aoarvlEbMGjDlq+XaNxgXHTdNCx/+FrJTyvYcjaRosehounSg4tm+B4/pja6e3q/u6naFWG1VtOTtF5UAJIWxGAhbhdIZ1CqWmtxtnrmSwdHe8bU9+04tqFCM3E6IehIzL6gt1zQfwx38ADTo/BkO/Ltgi4Fr+9eCRFdDqLhVoLHkWlr2oNnYsi6ung3RX7aUU1BICGkNetpqmqqw2fqpGiQxu0PcVdezA4qoxApGXC2d2qsd1O6sKt/W6qZ9lWqhyyM2CXb9AxhVH90SUQgIW4XQ8XA08nL9z85erj2M02nBVjl4PQ2eCf324clJtwLhiskqmBRXQDPpAtSuJmxfc9yP0m6x+3joTfr7b+mRcTSsIRq6eDgIVvFT21UIx6+DvN9Tj29+F3hNVLlHauaqRmHp2n5o+dPdT+z9BwbRQVfh8N4LNX8Lip+GftxzdE1EKCViEU3qoe3183F04ei6Vvw+ete3JqwXA/T+Bi4ca3dj8uTp++7tw8+TCoxwl0enUtgH3/6x2kI5ZAxtnWNeXcwfUxo0uHtCg1/XPt8jPYznyl2Wrm652dj/ErLXuNbaUkqiWkmtGaDdcrbQyuBbk5uxf6Li+2Yop4bZux4Igt35PdX9yY+WosHyji9ui7h35/4qwiAQswin5erjyYPf6AHyx+jg23/IqOAwGf6Qe6www5Cvo9lTZztUyAu78VD3e/DlkWlH4zjQd1PAmtZrpWnU6gk+wyomwpvBd0hn47jb48U7H5FLk5cBvY9RISlBrtcrKFAi2HqruDywp+zSaszAHLF0KjgW3BxdPyLgE5w87pFuVmqbBumlq5MMeEnar+4tHIe2ifd5TlIkELMJpPdKzIe4ueqLjrrDpRAX8IgkfCSPnwWP/qJ2dy6P1UKjRVK2G2faN5a8rbjrIRK+HFoPV44NLLD/vny+qIAdN7SJsb3+/Aac2qQTU+38qnLzcsA94Bqi6OLHr7N83WzIHLJ0Ljrm4QWj+zzItZL0Tq9X0zPKXi1/NZyup59UIp4lptEU4JQlYhNMK9HFnWKdQQOWyVIimAyAkvPzn0RvgphfU440zLCuOlnFFLX8FaNK/+HamKZTDf1qWqHroj8I5L3vm2neV0f5FsCl/amzIF4VXPgEYXKDVnfltK/G0UNrFgpVPdTsWfu7qaSFhnY2fFjz+fSKcPVBx72UaXTGpSsvtLWU0wuJxauWkk09hWh2wrF27loiICEJCQtDpdCxatKjE9gsWLGDAgAEEBgbi6+tL9+7dWbFiRaE2+/fv55577qFBgwbodDo++eQTa7slqqjHb2qEQa9j3dEL7D2d5OjulKzNPVC9oZoKsGRU48Qq0PJUsmZAw+Lb1e+pElXTLxQEOMXJSoFl+YFTzwlq1Cc7Ffb+ZumnKJ8LR2HxM+pxj+cKgq1rtb5b3R9coqaPKiPT6ErNZuBZvfBz5sRbyWOxSsIetYxfp1fTbLkZMHdUxVVHTohW9675I4CnbsARlrN7YdfP6ndW/E5H96ZEVgcsaWlphIWFMWOGZcmFa9euZcCAASxbtowdO3bQr18/IiIi2LWrYK+N9PR0GjVqxLvvvkvt2rWt7ZKowkIDqnFnWAgAX6w+5uDelMLgAr3/ox5v/Ayy00tuX9p0kPm8rtB8oHp8cGnJbVdNVUPc/vWhz0vQ6WF1fPsPFf/FmZ0GUfnF4er3hFv+r/i29XuCV6BaVh5Thk0pnUFR00EmdTqpqsgp8XA51q7dqtQ2fqbuWw2BByLBJ0Tllvw+oWL+/ZoClnb3q/v4XdYnt1d2V+fGRUc6rh8WsDpgGThwIG+//TZ33323Re0/+eQTXnzxRTp37kzTpk2ZMmUKTZs2ZenSgl+8nTt35oMPPmD48OG4u7tb2yVRxT3VV00pLN+fyLFzTr4PTdhw8Kunkk13/lh8O6PxqoBlQOnnvbrqbXG/uOOjYUt+ouLgj1TeSNgDYHBXlXnPVOBfT8Y8WDoBzh8E71pw7w8qgCuOwQVa5k8L7auk00JXV7i9lls1qNNBPZZpIctcOQX75qvHPZ8Dr5pw3w8qKX7vbxWTi2WaEmo9VFWwzstS/x/dSK5eHbVvnlPvNG73HBaj0UhKSgoBAQHlOk9WVhbJycmFbqJqalbLh/4ta6FpMHNNBeWy2IrBFXo/rx5vmA45mUW3S9ytgho3b7VfUWka36yGrZPirp93h/yAYbxaQtzmHmianxNTLQDa5P9xURG/8NMvwYZP4dNw2DtXfbncNwt8apX+WlO/Di0t2y9JR061GPMKF4wrytXTQtY4uRFmdK7cxQLLYvOXaoq04U0FeWX1ukH/N9Tj5S/bNphIv5S/aSVq1aCp4N+NlMeSm13w79PFU414Hl1R8mscyO4By7Rp00hLS2PYsGHlOs/UqVPx8/Mz30JDQ23UQ+GMnu6nRlkW7jpD/JUMB/emFO1Hgm8dSEmA6J+LbmP6MmrUF1wsGFV09YQmt6jHRU0Lbf1aDW97+MFtUws/1zF/WmjffNtV80zYrXJVPmoJK19TRfg8/OHOzwq+qEtTr7sajclMUitDrLFiMrxVA77qrXJ29s6z7WaUpTl/SOUGuXmrisRFMSfeWrFSSNPgz5fgwhH4580bJ/8l4zLsyB+R7DG+8HM9noXmg1XF599G2+7fcGL+1hzVG6j9wkK7qp9vpDyW+J2QkwbVakDnserY7l8d26cS2DVgiYyM5I033iAqKoqgoKBynWvSpEkkJSWZb3FxdvxlJeyuQ73qdGsUQK5R45t1J0ptn51rJDruCpfTHDC86eKuEl4B1n1c9OiBuRy/BdNBJqYplGur3iadhn/zK/X2f/P60Y3QLqoWSm4G7Imy/P2ulZutAoPvboWZN8Gun9QWB7XbqkBl4kG1VNxSeoPKVQDYb8XeQifWqFVIWp760tn6NcwfC5+0gY9awW8Pw5aZ6q/xiqrzEpc/HVSng/ocRQntopJHL8dAsoVbTBxdWfBFmrhX5VTcCLZ/r744g1oXBOYmOh0M+VxtiXE5Vq1osUUgZxqtCQ5T9+YRli03TqBoyl9p0Fv9oQVwZIXT1qOxW8ASFRXF2LFjmTt3Lv37l7CE00Lu7u74+voWuomq7em+TQD4dWscl4oIRHLzjKw/eoGX5++h8zt/M+TzDXR/9x/eWLKfuEulJMDaWoeH1OhB8mnYfU0iW9rFgg3zmlgRsDS9FfQu6q/7C0cLjv/5kvprP7QrdBh9/et0uquSb7+3/pdxdhqsmgIft1aBQdwW1Y8296o9lZ5YBx1GXb9RpCVMReQO/WFZsmN2mtq7CSD8QTX91PUpNYWgM6iE4/0LVB2ar/vA+w3h8HLr+1Waqzc8LI6HnwrmwLJpIU2DdR+qxy4e6r6kPKiqIicTNn+lHvd8ruhK057V1VYYBjcVsG/+ovzva5paDW6ffx+m8r3SL8BFJ596thVTwnvDm6BWK3UNjDkFuUROxi4BS2RkJGPGjGHOnDkMHjzYHm8pqqDeTWvSpo4vGTl5zNoQA4DRqLEt9hKvL95Ht6n/8OB3W/h1WxxJGTlUczOQmWNk1sZY+n64mvG/7uJAvJ1ynVw9oWf+0Pa6aYWX7h7/B9DUzr5+dSw/p6e/+sUCBdNCB39Xv8D1LnDHJ8XvgdRumMqBOX9IFXSzlKbB/MdgzXsq58a7ttrA8Pn9cO936q9SS7cyKEpoV7USJCsZjv1Tevt/31bTT36haiuF1kNh4Lvw+GqYFAejl0K/V1VdG3c/dV7TyhNbMifcdim5nTX1WGLXq2DQ4A535W8XsXdexS3pdRZ7otS/Ld86Kv+qOHU6wG1T1OOVrxeMcpWVOWDJH2FxcS9IlL4R8liy0wuuYaO+6j4sv4DmtX9kOQmrA5bU1FSio6OJjo4GICYmhujoaE6dUslLkyZNYtSoUeb2kZGRjBo1imnTptGtWzcSExNJTEwkKamgpkZ2drb5nNnZ2Zw5c4bo6GiOHXPyZazCrnQ6nXmUZdbGWN754wA93/uX+77axOxNJ7mQmk31aq6M6FqPyMe6sfeN2/h5bFd6N61JnlFjcXQ8gz5dx6jvt7Lx+AXbl/u/VseH1cqDKycL10Epy3SQydWrhbJS1EgCqJontVoV/zoPP2h7r3q8/QfL32/7d3D4D/WX7d3fwPP7oO9L4GOj8gN6PbQeoh6XVkQubmtBufaIT8Ddp/Dzbl4qoOvzAjw4H55ar46f2gip52zTX1D5FheOqMd1O5Xc1prEW9PoSviD6ou7RhM1cuakf+3ahNFYEFB2e7r4HdJNOj+qavgYc/O3fijj1EVmMlzKH0UxjbDAVXksN0DAcmqTGk3xrQMBjdSxNveqP37idzrlthJWByzbt28nPDyc8HCVxT1x4kTCw8N5/fXXAUhISDAHLwAzZ84kNzeXcePGERwcbL6NH1+QWBUfH28+Z0JCAh9++CHh4eE8+uij5f18ooq5rXVtGtX0Ijkzl2/WxZCQlIm3uwt3d6jDrIc7s3Vyf6YMbUv3xjUw6HX0alqTn8Z25fdne3FHu2D0Olh75DwjvtnCkM83sGxvAnm23A36am7VVMIgwNoP1coSYx4c+1sdK63+SlGaDwZ0cGaHmhpJPqOSBk1VdkvS6RF1f2CRZb/ozx5Qya2gVmq0G1b6F0pZmKaFDi+DnGISqnOz8gvSaRA2ouTKwCb+9SCkg1o5Zcvdrk/vUPfVG6qltyUxrQA7f7Dka356h0o81hnUyJxOp6bZoGpPCx35U9VZcfeDjkVMZ15Lp1P7dtVoov7tL3yibPkmpjwhv1DwqlFw/Oo8lqrOtJy5YZ+CUVLvwIJpaiccZbE6YOnbty+apl13mzVrFgCzZs1i9erV5varV68usT1AgwYNimxz9XmEADDodbwW0Yq61T0Z3C6Yrx7syPZX+/PRsPb0bR6Eq6Hof9Jt6vgxY0QHVv+3Hw91q4+7i57dp5N4+pedDJu5ifTs8iVn5uYZOX25iDyZzmPV/Pul47BvgQo0Mi6rX9ClTScUxaeWSuaEghGJwdMsyx8JCVd/TeZlQ/QvJbfNyVA7Ledmql9gXcu4MaQl6nQC37pqNMEUzF1rzftw4TB4BcFt71h+7lZ3qfsDi8vfTxNTwbhQC/77edWEwBbqcUlTcabRlXb3Q3W16SdhI1TxuTM7IHFf2fvrzDbkl+Hv/Mj1I2bFcfdR+SwuHnBsZdnq3Fw7HWRiGmG5cEQte7a1hD2w/BV1s2SbjYpkyl9p1KfwcdO+arujHN/Ha8heQqLS6dc8iPUv3cznIzpwe5vaeLgWs0qjCPVqVON/Q9qw4eWbee7mJvi4u7Dj5GWej4rGWMaRlrSsXO6buYle763izaX7yckzFjzp7gPdxqnH6z6EI/kJoE1uLrmwWkmuLnff5l7LRhtMTKMsO2ap4fji/PWqGhXwCoIhXxafG2MLpU0LJeyB9R+rx4OnqdoyljLtWRSzznYrH0qqcFuU0qaFzu5Xo0vooPfEguPegdBikHpcFUdZTm1RuSIGN+j6pHWvrd2mIBg1TbFao7iApVqA2moBbDfKknZRJRV/1Qtm9lY7um/+vHDBNnvLuFxwDUx5cSbNbldTyCnxju1jESRgETekmt7uTLy1OT883Bk3g54V+8/y7vJDVp8nKzePJ37awa5TVwD4YUMsD367hQupV6146fq4GlE5f6ggB6Ms00EmLe9Uf3l7+BckIVqqzT1qB+VLxyG2mF9GB3+Hbd+qx0O/Ul+cFc20t9Dh5YW3NMjLyV/Gmqe+oEwBiKUCGkHtdur1h/8ofz+NRstWCF2ttHos66ap+1Z3Qc2mhZ/rOEbd744qfauHysa0yWG7YWXLiTL9P1SWAnvXLmm+mi3yWPJy1WalUQ/CtOaw/CW1TN3gprakAMcuWY/doKZKazQF35DCz7m4FyQ/O1lNFglYxA2tU4MAPrivHQBfrz3BnC2nSnlFgTyjxvNR0aw/doFqbgZeur0F3u4ubIm5RMRn69kdd0U19PCDbvl/Qebkf+lYMypyrer14bF/4Yk1llWUvZq7t/qCgKIr3yadgSX5mxd2f+b6mhgVpU4HlXOSk1b4L+aNn6p8A8/qMOjDsp3bltNCF49CVpKqClqrtWWvMeWxJO5RyZ6Fzne8YFTJtA/V1Rr2VftCZSWVrf/Zac65ueSFY2opO6iE8bJofLOqc3Nuv6pFZKnstIKk6asTbk3Kk8dy6YQanfyoJUQOV6v5jDnqfQZ+AP85XJDXZtrHyBHM+Ss3Ff182Ah1f3CJfXd6L4UELOKGd1f7OkwcoIaBX1u8j7VHzpf6Gk3TmLxwL8v2JuJm0PP1Q514qm9jFo3rQaNALxKSMrlv5ibmbs8vaNj1SXDLn6MPCQfv8hVOJLidSrYtC1Pl20N/QMrZguPGPJXEmHFZ/YItafNCW9PpCpJvTUXkzh+B1e+px7e/W/ZrZipOd2K1+mzlYVoGGhJueQKyXx3130ozXr8Ud/1H6njT29R/02vp9aqmD1g/LXTpBExvD591gMsnrXttRdv0GaBBs4EQ2Lxs56gWoPKfoPjcp6Ik7lPv7V276IA/ND9gObPTuo0QU8/B133Vqqe0c2qFYLdx8OQG9cdF18dVn01BkiNHWIrLXzGp2wkCGqs/sErbcNWOJGARAnj25ibc3aEOeUaNp3/ZyeHEkv+qeG/5YX7dFodeB9OHt6dXU7VapEmQD4vG9aR/y1pk5xp5cd4eXlu0j2w3f1UUC1TeiSPVbqOGvY25qlqtyfqPIHYduHrBvd+Di5t9+2UKWI78pUYiljyjNqNr0r9gN92yqNlEVVA15g/Tl4c54dbC6SCToqaFrsQVDLnf9N/iX9v+QbV66NQmy5ea5marpOm0c2q/nJ+G2HZpd3mknivYFdhUq6isyjItVFz+ikmNxgUbIRa1b1dxtn2ntpmo0QSGz4H/HILbp6j/365met8rpyomsbc0KWfV9DQ6VeG2KDpdQfJt9By7da00ErAIgarxMvXutnRpGEBqVi6PzNrGuZSiNy6cueY4X+VvwjhlaFsGtg0u9LyvhytfP9SR5/urUZufNp9kxDebOdf+WXh6i6o34WimUZYdP6qRlbitsCp/D6JBH6hf2vYW3F4tFc7NUHP/cVvUXj13fFK+4nRgu2kha/NXTIpKvN34qQqiGvQuecWRbzA0u0093jnbsvf75031F7yHv5pqu3QCfrrbdvvwlMeWmSoYqNu5YPqlrEy1jE6stnw0xDQVE9K+6Od1OuvzWHIyC/K++k2GFoOLH4Hz9C+oe+KIURbTdFDttiUnsJv+SIhdV7BJpINJwCJEPncXA18/1JFGNb04cyWDx37cTkZ24WV9UdtOMfVPlZz78sAWDO9Sr8hz6fU6xvdvynejO+Hj7sL2k5e5Y8YGdmTUqtgVN5ZqPUR9mSWdUjkU88eqxNQ290L7EY7p09XTQqYh6wFvgr8NNjY1BSzH/1V/BZdFZjKcO6AelzVgObNDLRlPPVcQfJQ0umJi2nIhek7pX8xHVqi9lgCGfAEPLVKrvc7uhTnDVA6Ho6SeL/hiN9WbKY/a7dRny061vIJzaSMsAPXyAxZL81j2zlUl/f1CC/b8KolpN2pH5LFcXY6/JP71CkZgyrMHmQ05wW9OIZyHfzU3vh/TmerVXNl9OomJcwuWOy/fl8CkBXsBeKJPI57sU/ooxC0ta7H4mZ40DfLmXEoWw7/exOrDTjA07+pZsNnZwifUX1D+9eCOj8r/JVIebe4ueFy/J3R8xDbnDWoBNZurGjRHVpTtHPE7AQ386lm/qqV6Q/AJVgmYp7ergCI3U+VgNCwmj+BqTfqriqQZl0rOKUiOh0X5NXO6PKH+0q/RGB5aqJK/47bA3FFFb8hZ0Q4shi+6QeYVNW3SfFD5z6nXF4yyWDItlJMJ5w6qxyUFLKY8llObSy9Mp2mwKX8rha5PWFauwJF5LOb8lb6ltzWX6v/VKTaElIBFiGs0qOnF16M64WbQ8+e+RN5bcYj1Ry/wXGQ0Rg2Gdw7l5dtbWHy+RoHeLBzXkwGtapGTpzFl2cEy13yxKdOSWWOuypG453v1peZItdqoLwvPALUDtC1Ho8o7LRRnqr9SSjn+ouh0BaMsh/5Q+Q6gRlcsCRANLqpkPxSffGvMgwWPQ/pFNfJw6/8KnqvdBkbOU/tJHfsbFjxmv6Jg6ZdUPs3cUWoUIqgVDPup+F2urWVNwHJ2vxpJrFZDBYDFCWlfsBHipVJ2hz/+j8oJcfMuqE5cGtMIS7wVOTK2cClG/XGidylYvVaSVneqfzMXj6nRQQeTgEWIInRuEMD796pVGzPXnOCRH7eRnWdkYJvavDO0LTorRyG83V348L4wfNxdOHI2lZUHz5b+oooW2Awa9VOP+02yPpG0Iuh0MOYPtWeRrfNozIXGVpZtqaY1FW6LYgpYts5UUxi12qgiXZYKfxDQqRyEonYTXjftqqTpH1Q9jauFdoHhv6gaPgcWwe/PV/xfzQd/h8+7qv2QdAbo/V+1UWVJ+15Zq1E/de4Lh+FybMltTVMwwe1LDhRd3AuCitLyWEyjKx1GWR7wm1aEJZ2yXUFDS5jyV+p0UiUOSuPuU1Co0gmSbyVgEaIYQ8LrMKG/KuSVnWukV5OafDK8PQZ92aZM/Dxdeai7Krv++apjFb/5oiXu+U7lOPS2II/CXgwuaiNDW6vVWi3VzMuyvjqqpllf4fZappVCWn6F4d4TrZt+869XUBfn2uTbkxthdX7S9B0fqZVRRWl8M9zzrapfsvNH+LuClq6nX1K7fEeNVCuVAlvAoyvhlteuD6TKy9O/IHm3tFEWS/JXTMx5LCUELGcPqLwonV5NB1nKw09NiwEk2HFaqLTlzEUJG67u9823bpl3BZCARYgSjL+lKc/3b8awTnWZ+VBH3F3KN4w9tldDPFz17DmdxLqjF2zUy3LwqgGN+zk2b8VedLqyTwtdOqHyRwxuanVFWdRsrqa6QH1ZmerDWOPq5FtTQbj0SzD/URUIhT1Q8AVTnNZDIGK6erxhesG2B7ZyaJnKVdk7V32R93oeHl8DdTra9n2uZirEaMuAxZzHUkLi7eYv1H2LO6yvi2TvPBZNK71gXFEa9gGfEJV7ZNpaxEHKuJmJEDcGnU6t9rGVGt7ujOhSn+83xDDj32Pc1MwOZe9FgVZ3qXozR1eq1TKWjuSYRleC25d9hECvV1NAu+dAn5fLlsPRfKBaFZN2TtWUaRkBi55WOxfXaGJ5NeAOo9Rqqb9ehb/fUPksdTqo3Aa9i5o20huu+tlFBXy5meqv7JwMdZ+boRJZc/NvpzbDvnnqPWo2U/tQlSXnx1pNb1VLuWPWqv64elzfJje7YJWXRQGLaSPEwyoovHYJcOo52DNXPe7+jPV9DmmvrpVpm4CKdu4gpJ1XVZqtGSXUG1R17A2fqORbU9DvABKwCGFnj9/UiJ83n2Rr7CW2xlyiS0MrNvMT5RMcpkrdXzmpkk8t/eVrqlBb1ukgk0EfQPenyz5KY3CF8JFqVGTnj2pV0JE/1cjPvT9Ylpdg0uNZVZdl3Yfw7/9KbW4xnV59gfebXHTgUBFqtVajACnxcHJ90VtfnD+oVol5+Fk2GuJVQ+21c/Go+u/f/Jp8o23fqenFOp3KltdkTryNtv61ZWEaXanXzfqgO+wBFbAc/QvSLqhdyB1ApoSEsLPafh7c07EuADNWHXNwb24wZZ0WKmuF22u5e5c9WDExrUQ59g+sfE09vvWdokv7l+bmV9UWDMHtoVZbCGypvqSrN1A1RXyC1WZ9ntXVF713LZVLU7O5WokU2lVNLzS9TdUfCX8QHlmhVijZK1gB9d+1tNVCV08HWToFWlwey9WF4ro/XbYp1dr5/72ST6sgwFqZyWpKz9JtF8qSv2IS1EIFWMY8iF1v/ettREZYhHCAp/o0Zu72ONYeOc+e01doV9ff0V26cbQaoqrMHlmhpjZcPUtuf/aAWg4L5R9hsYWARipIiFmrRgxa3AFdHivbuXQ6lfzbe6Jt++gITQeoUaejf8HA965/3pr8FZPQbrDr5+vzWAoViivjFImHb8EITnw0NLVyQ9SNn8LaD2DTFzB6qVr1V5y83IJAw5K6P0UZ/JHaz8uvbtlebwMywiKEA9SrUY07w9S27p/LKIt91ekAvnXV0uLj/5bcNmYdfH+7qt1Rp1PJtTvsqdNYde9bV9WruRGSpkvTsI/Kvbl0ouhl36apl6J2aC6OafVR/M6CYntlKRRXHNP2AGVJvD20TN2nJsKswXDuUPFtE3ZDVrIaJbMmYLtanQ4ODVZAAhYhHObpvqrOyIr9Zzly1rq6IGeuZHApzQHVSqsCS6eF9s6Dn++GrCT1l/bI35wnMGh1F9z/CzyyvOT9YG4kHr5QP78Y2rXTQnm5cHafemxNwFKjiSoyl5tZMEJTlkJxxSlrif4rp+DcflV/Jqi1SsKeNViNBhbFNB3UoLftCvY5gAQsQjhI01o+3N5alXj/wopRlsXRZ+jz/ip6v/cvc7fFOUc9l8rGFLAcXn59bQlNgw2fqv2V8rJVbsaoRc4VGOh00PIO2+yzVJWYd2++ps7OhSMq6HDzLth40BJXb4RoymPZlL+UOfyh8leGLuvS5sP5y4vrdYMxv6tRk/QL8OMdkLj3+vaW7h/k5CRgEcKBxvVTxaOW7I7n5MXSN6WbvSmWCVHR5Bo10rLzeHH+Hh7/aQcXUh1b0KnSqdtZJZRmJcGJNQXHjXmw/OWCZNauT8J9s0rPcxHOwRSwxK4vvMmjaQSjdjvrt3u4eufmswfUCIu1heKKE9wO0Kll6alW7DF25E913+x2FUiPWgwhHdS2DD9GFIwGgUoQNlXrLWv+ipOQgEUIB2pb148+zQIxavDl6iLm3fNpmsb0v4/y+uL9aBqM7l6flwe2wNWgY+WBs9z+yVpWHnCCcv+VhV5fsKuuaVooJwN+Gw1bvlI/3/oO3P5upR5Cv+HUbKY2p8zLUvlHJqYvcFPOiDVMeSxxW2Bzfu5Ki8EQ0LBcXQVU6fua+XWeLF3enJVSkEDbfKC696yuRgHrdoaMyypoObNTPXd6mxpd8q4Fgc3L32cHkoBFCAd79mY1yjJ/52nir2Rc97zRqPHm0gN8/PcRAJ7v34w37mzNk30as3hcL1rU9uFCajaPzd7Oy/P3kJqVa9f+V1qmaaFDv6u/bmcPUTshG9zg3u+hxzPOk7MiLHP18uZjV+WxlGWFkElwe/VvIu08REeqY2UpFFcca/NYjv+rpioDGhcEO6Cmpx5coEaEMpPUv+fTOwpPB1Xyf88SsAjhYJ0aBNC1YQA5eRpfry28M2xOnpHn50Yza2MsAG/e2Zrx/ZuaN19sFeLL4md68sRNjdDp4NdtcQyavo7tsZfs/TEqn3rdVNXYzCuqlHzcZvVL/6GF0OYeR/dOlNXVeSyaBkYjJOxRx8oSsLh6FAQVWp7aYsA0TWQL1uaxmPJXTKMrV/PwhQfnq52Ys5LgpyGw9zf1XCWfDgIJWIRwCs/kj7L8uu2UOR8lIzuPx2dvZ3F0PC56HdOHt2d0jwbXvdbdxcCkQS2JfKwbdfw9OXUpnWEzN/H+8kNk5xrt+TEqF71BJa6Cmvv3rauKnjXo5dh+ifJp2BsM7molzYUjcPEY5KSpkvQ1S6hVUpKrA5Tu42w7UmFNxVtjHhxdoR4Xt9O3uw+MnAf1e6mlzKYdrCt5wi1IwCKEU+jVpCZhdf3IzDHy3foYkjJyeOi7Law6fB4PVz3fjO7EXe1LrgHSrVENlk/ozb0d62LU4IvVx7nny40kZeTY6VNUQu1HAjqo1UbtJhzU0tE9EuXl5lUQdB79q2A6qHbbsucjNeit7stTKK44tdsCOrWtQEopeWint6vg2sOvILemKO7eMHJuQZBSvSFUr2+zLjuKBCxCOAGdTmdeMfTTppPcP3MT209extfDhZ/HdqVf8yCLzuPj4cqH94Xx1YMdqV7Nlb1nkhj/6y7yjLL0uUh1O8Hz++Hx1eAb4ujeCFu5uky/KTekrAXTTOe78zMYMbd8heKK4u5dkAxbWh7L4fxicU0GqH2lSuLmBQ9Eqe0XhnxZ7m46AwlYhHAS/VvWonktH1KzcjmUmEKgjztRT3SnUwPr63/c3qY2P43tioerntWHz/PhX4croMdVhF+d0n/5i8rFlMdyciOc3KAelydg0elUkbharcrft6JYmsdypIT8laK4VYObXigoqFfJScAihJPQ63U8P0Bl/dcLqMb8J3vQMti3zOdrU8eP9+5RG6x9ufo4S3bH26SfQji9Go1VgThjTkEQUJYlzfZiLtEfXXybSzGqwq7OAE1usUevnI4ELEI4kdvbBLNiwk0sn9CbejWqlft8d7Wvw5N91BYAL87bzb4zSeU+pxCVgmmUBdSy5MAWjutLaSxZ2mwaXanfQ9VduQFJwCKEk2le24dqbrabJ3/htub0bR5IZo6RJ6QqrrhRNBlQ8LhWa+ee9qvdVlXPTUmAlMSi2xy+qrrtDcrqgGXt2rVEREQQEhKCTqdj0aJFJbZfsGABAwYMIDAwEF9fX7p3786KFSuuazd//nxatWqFu7s7rVq1YuHChdZ2TQhRBINex/Th4TSs6cWZKxk8/ctOcvJkubOo4hr0VEuZwboNDx3BzQtq5ifeFjUtlJlUkItjaf5KFWR1wJKWlkZYWBgzZsywqP3atWsZMGAAy5YtY8eOHfTr14+IiAh27SpILtq0aRP3338/Dz30ELt37+ahhx5i2LBhbNmyxdruCSGK4OfpyjejOuLt7sLWmEu8tbSYXV2FqCpcPaFpf/W4XiVIOjXnsRSReHvsHzDmQo2mKj/nBqXTyrHVq06nY+HChQwZMsSq17Vu3Zr777+f119/HYD777+f5ORk/vzzT3Ob22+/nerVqxMZGWnROZOTk/Hz8yMpKQlf37InKgpRlf194CyP/bQdTYN3727L8C71bHLe5MwcPvvnKD2a1LR4CbYQFS7tgtp3p+Wd1m96aG9bZsKfL6opnxFRhZ9b8DjsiYIez8KtbzumfxXI0u9vu/8XNBqNpKSkEBBQsFRz06ZN3HrrrYXa3XbbbWzcuNHe3ROiSuvfqhb/GaCqfb62eB87TtqmhP9bSw/wzboYxs7aJquRhPPwqgmthzh/sALFL23Oy1UF8ACa3bjTQeCAgGXatGmkpaUxbNgw87HExERq1apVqF2tWrVITCwm+QjIysoiOTm50E0IUbpx/ZowuG0wOXkaT/y0k4Sk6zdctMa6o+eZt+M0AEYNJvy6i6UStAhhHVPibepZSE4oOH56q9qB2cPftnsYVUJ2DVgiIyN54403iIqKIiio8LCx7pq9GTRNu+7Y1aZOnYqfn5/5FhoaWiF9FqKq0el0fHBfu/xdnrN44qcdZObklelc6dm5TFqwF4CHutXnvvxtASZERfP7HglahLCYW7WCpddXj7KYVgc1vdX2VXYrGbsFLFFRUYwdO5a5c+fSv3//Qs/Vrl37utGUc+fOXTfqcrVJkyaRlJRkvsXFxVVIv4Woiqq5ufDNqE5Ur+bKntNJvDR/D2VJZ5v21xFOX84gxM+Dlwa24L172nFvx7rkGTXG/xrNsr0JpZ9ECKEUVY/FXN32xl3ObGKXgCUyMpIxY8YwZ84cBg8efN3z3bt3Z+XKlYWO/fXXX/To0aPYc7q7u+Pr61voJoSwXGhANT4f2QEXvY7F0fF8sfq4Va+PjrvCDxtiAHjn7rZ4u7ug1+t475523N2hDnlGjWcjd/GnBC1CWObaPJaLx9WO03oXaNK/2JfdKKwOWFJTU4mOjiY6OhqAmJgYoqOjOXXqFKBGPkaNGmVuHxkZyahRo5g2bRrdunUjMTGRxMREkpIKKm6OHz+ev/76i/fee49Dhw7x3nvv8ffffzNhwoTyfTohRIl6NK7Jm3e1BuCDFYf5a3/xeWNXy8418tK8PRg1GNI+pNDKIINexwf3hnF3eEHQsnyfBC1ClMo0whIfDZpWuLqth5/DuuUsrA5Ytm/fTnh4OOHh6sJOnDiR8PBw8xLlhIQEc/ACMHPmTHJzcxk3bhzBwcHm2/jx481tevTowa+//soPP/xAu3btmDVrFlFRUXTtemMnGAlhDyO71md0d7X1/ISoaA4mlJ7A/tWa4xw+m0KAlxuvR7S+7nmDXscH94UxNLwOuUaNZ+bsYvk+y4IhIW5YtduovYLSzkFy/FXVbW/s1UEm5arD4kykDosQZZebZ2TMD9tYf+wCdfw9WfxMT2p6uxfZ9ti5FAZNX092npHpw9tzV/s6xZ43z6gxcW40i6PjcdHr+GJkB25tXbuiPoYQld+XPeHsPhjyJSx5VhWMe26X2syxinLaOixCCOfjYtDz+YgO5vL9T/28g6zc61cOGY0aL83fS3aekX7NA7kzLKTE8xr0OqbdF8adYSHkGjXGzdlp8bSTEDckUx7L+o9VsFKzeZUOVqwhAYsQAgC/aq58M6oTPh4ubIu9zKsL9123cuinzSfZcfIyXm4G3h7atsTSAyYuBj0fDQsjIiyEnDyNp37ZyU+bT1bUxxCicjOV6L9wRN3L6iAzCViEEGZNgryZMaIDeh38tuM0362PMT935koG7y8/BMBLA1tQx9/T4vO6GPR8PCzMvOT5tUX7eHPpfvKMVWJGWgjbMSXemkj+ipkELEKIQvo0C+TVwa0AmLLsIKsOnUPTNCYv3Etadh6d6lfnwa71rT6vi0HPB/e244Xb1K60P2yI5fHZ20nNyrVp/4Wo1Gq1Vom3AJ4BENrFsf1xIhKwCCGu83DPBgzvHIpRg+cid/Hx30dZffg8bgY9797TDr2+9Kmgouh0Osb1a8LnIzrg7qLnn0PnuO+rTcRfKd/2AEJUGa6eEKT+YKDpraA3OLY/TkQCFiHEdXQ6HW/d1YYuDQJIycrl03+OAvDszU1oEuRd7vMPbhfMr493o6a3OwcTkrnr8w3sOX2l3Oc10TSNX7ac5M4Z69l0/KLNziuEXbQZqorFdRzt6J44FVnWLIQo1sXULO76fAOnL2fQorYPS57phZuL7f7OOX05nUd/3M6hxBQ8XPV8cn97bm8TXK5zpmTm8PKCvfyxRxWrax3iy+/P9rIoQVgIp6BpaoWQwdXRPbELWdYshCi3Gt7uzH6kCw90qcfnIzvYNFgBqFu9Gr892Z2+zQPJzDHy5M87+XL18TLtawSw93QSd3y2nj/2JOCi1+Fq0LE/PpldcVds2m8hKpROd8MEK9aQgEUIUaJGgd5MvbstjQPLPxVUFB8PV74d1YkxPRoA8N7yQzwfFc2xc6kWn0PTNGZtiOGeLzdy8mI6dfw9mftkd+4MU0Xtft4ky6iFqOxkSkgI4TR+3BjLm0v3Y1rt3LF+de7vFMrgdsF4ubsU+Zqk9BxenL+bFfvPAnBrq1p8cG8YftVciY67wpDPN+Bm0LP5lVsI8HKz10cRQljI0u9vCViEEE5la8wlvl57nFWHz5vrtFRzM3BHu2Du7xxKh3rVzfkou05d5pk5uzhzJQM3g55XBrVgdI8G5uc1TePOGRvYeyaJlwe24Mk+jR32uYQQRZOARQhRqZ1LzmT+zjPM3R5HzIU08/HGgV7c3zmUPCNM++swuUaNegHV+HxEB9rWvX5H27nb43hx3h5CAzxZ/d9+GMq4JNuZpGfn8svmU3RvXIM2dWQXX1G5ScAihKgSNE1jW+xlorbFsWxvAhk5hfc4Gtw2mKn3tMXXo+gkxYzsPLpN/YekjBy+H9OJm1vUske3K0z8lQwem72d/fHJNA704u+JfWQFlKjUZJWQEKJK0Ol0dGkYwLRhYWydfAtThrYlLNQfb3cX3h7ShhkjwosNVgA83Qzc17EuAD9V8uTbXacuc9fnG9gfnwzA8fNpHD6b4uBeCWEfRWexCSGEE/LxcGVE13qM6FoPTdMsHlkY2a0+366PYfWR85y6mE69GtUquKe2tzj6DC/M20N2rpHmtXzw9VSbVP6xJ4EWtWVUWVR9MsIihKiUrJkGaVjTi95Na6Jp8MvWyjXKYjRqfPTXYcb/Gk12rpFbWgQx/+kePNhN7ef0x56EMtetEaIykYBFCHFDGNW9AQBzt8WReU0ejLNKz85l3JydfPrvMQCeuKkRX4/qhLe7C7e0rIWbi54TF9I4mCDTQqLqk4BFCHFDuLlFEHX8PbmcnmMu2+/MEpIyGDZzE3/uS8TVoOODe9sxaVBL8yonb3cX+jYLBGDZXuf/PEKUlwQsQogbgkGvY0TXegD8tLn800KZOXkcSkzm9z3xTP/7KM9G7uLVRXvJyi3/6E103BXumrGBfWeSCfByY85j3bivU+h17Qa3U/su/bFXpoVE1SdJt0KIG8awTqF88vcRouOusPd0UpF1W4oScyGNbTGXOH4+lWPnUjl2PpW4S+nmirxX83JzYdKglmXu47qj53n0x+1k5SfXfju6E6EBRScJ39KyFu4uemIupHEgIZnWIVKTRVRdErAIIW4YgT7uDGwTzJLd8fy8+STv3duu1Nf8tCmWN5YeMFfdvZqPhwtNgrxpHOiNr4cr32+I4et1J+jTPJAejWta3b+EpAyei9xFVq6Rm1sE8ekD4XgXsyUBqGmhfs2DWL4/kT/2JEjAIqo0CViEEDeUUd3rs2R3PIt3n+GVQS3xq1Z0DZecPCNvLNnPL1tOAdChnj/t6vrTOMibxoFeNAnyJtDbvdBqpfTsXH7dFsd/5+7mzwk34edp+Y67uXlGnp2zi8vpObSp48sXIzvg4Woo9XWD2wWrgGVvAi/c1lyKyIkqSwIWIcQNpWP96rSo7cOhxBR+2xHHo70bXdfmUlo2T/28gy0xl9Dp4MXbWvBkn0alBgOv3dGKTScucvJiOq8v3sf04eEW92vayiNsP3kZH3cXPh9hWbACKpnYw1XPyYvp7I9PllL9osqSpFshxA1Fp9PxUHdVw+SXLacwXjPVczAhmTtnrGdLzCW83V34dlQnnurb2KKRCy93Fz6+vz0GvY7F0fEsjj5jUZ9WHT7Hl6uPA/DuPe2oX8PL4s/jlT8tBPB7JVj9JERZScAihLjhDGlfBx93F2IupLHh+AXz8RX7E7nny42cvpxB/RrVWPh0D25pad3eQx3qVefZm5sA8OqifZy5klFi+4SkDCZGRQNqusq08scaptcsk9VCogqTgEUIccPxcnfhnqv2F9I0jc/+OcoTP+0gPTuPnk1qsHhcT5rW8inT+Z/p14T2of6kZObyn7nR143imORck7cyeXDZVheZpoVOXUpn35nkMp1DCGcnAYsQ4ob0YDdVk+Xvg2d59MftTFt5BIAxPRow6+Eu+FdzK/O5XQx6Pr6/PdXcDGw+cYlv158ost20vwrnrbi7WJa3cq1qbi7ckr8L9e9748vcbyGcmQQsQogbUpMgH7o3qoFRg38OncPVoGPq3W15487WuBrK/6uxYU0vXr+jFQAfrDjMgfjCIx+rDp3jqzUqb+W9e63LWymKuYicnfcW0jSN8ylZbI25xNLd8aRm5drtvcWNRVYJCSFuWGN7NWTTiYvU8HLjywc70qVhgE3Pf3/nUP4+eI6/D55lQtQuljzTCw9XA/FXMpg4NxqA0d3rM6it9Xkr1+rXPAhPVwOnL2ew53QSYaH+5T7n1VIyc4i9kM6JC6nEXEgruJ1PI+WqIKV9qD8/P9q1xPoxQpSF/IsSQtyw+reqxeJxPQkNqEaAV9mngIqj0+l475623PbJFY6cTeW95Yd4ZVBLno0syFt5pYx5K9fydDNwS8sgft+TwB97E8odsGiaxtFzqazYl8iKA4kl5sbodFDH35Ok9Byi467w2I/b+eHhzhYvzRbCEjqtiqSUJycn4+fnR1JSEr6+vo7ujhBCmK06dI6HZ20DoF/zQFYdPo+Puwu/P9er3FNBV/tzbwJP/bKTOv6erH+pn9VF5IxGjejTV1ixP5G/9p8l5kJaoedrervRsKZX/s2bhjW9aBToRb2Aani4Gtgdd4UR32wmLTuPW1oE8dVDHW0yvVZWRqPG2ZRMgv08HdYHUTpLv7+t/pe0du1aIiIiCAkJQafTsWjRohLbJyQkMGLECJo3b45er2fChAnXtcnJyeGtt96icePGeHh4EBYWxvLly63tmhBCOKV+LYJ4qJuq/bLq8HkA3rdB3sq1+jYPopqbgTNXMth9Osmi1+TkGVl/9AKvLtpL93f/4e4vNjJzzQliLqThZtDTr3kg797dlm2T+7P91QH89mQP3r83jKf6Nub2NrVpVsvHPJISFurPd2M64+6i559D55g4d3eRWxrYQ/yVDO79aiPdp/7LvV9uZPm+BIf1RdiG1VNCaWlphIWF8fDDD3PPPfeU2j4rK4vAwEAmT57Mxx9/XGSbV199lZ9//plvvvmGFi1asGLFCoYOHcrGjRsJD7e8UqQQQjirVwa1ZMPxC5w4n8aYHg0YaIO8lWupaaFaLN0dzx974mlfyrTQ0bMpPP3LTo6eSzUf83Z3oW/zQG5rXZu+zQPx8bB8ewGAbo1q8NVDHXl89naW7o7Hy83A1Lvb2nXLgNWHz/F8VDSX03MA2H7yMttPXiY0wJNHejbkvk6hkmNTCZVrSkin07Fw4UKGDBliUfu+ffvSvn17Pvnkk0LHQ0JCmDx5MuPGjTMfGzJkCN7e3vz8888WnVumhIQQzi4hKYNNxy8SERZSYVMly/cl8uTPOwjx82DDyzcXGygs2HmayQv3kZGTh381V25vXZvbWtemR5MaZV5efbU/9iTwbOROjBo82qshkwe3rPCgJc+o8cnfR5ix6hiaBm3q+PLmnW1YdegcP285yZX8AMbHw4UHutRjdI8G1PGX6SJHs/T72ylCzKysLDw8PAod8/T0ZP369SW+Jisry/xzcrIUSxJCOLdgP0/u7lC3Qt+jb/NAvNwMxCdlsivuCh3qVS/0fGZOHm8u3U/k1jgAejWpySfD21PT292m/RjcLpi07Ha8OG8P366PwcfDlfH9m9r0Pa52LiWT8ZHRbDpxEVB1dl4d3AoPVwMd61dnXL8mzN95mu/Xx3DiQhpfrz3Bd+tjGNQ2mEd7NbT5qiphe05Rh+W2227jo48+4ujRoxiNRlauXMnixYtJSCh+X4ypU6fi5+dnvoWGhtqxx0II4Zw8XA30b6WKyP1xzd5CsRfSuPuLjURujUOngwn9m/LjI11sHqyYDOsUaq5F8/HfR/h2XdEF9Mpr84mLDP50PZtOXKSam4Hpw9vz9pC2hVYpeboZeLBbff6e2IfvRneiR+Ma5Bk1lu6O567PN/DMnJ1cTssuVz80TSu2qrEoP6cIWKZPn07Tpk1p0aIFbm5uPPPMMzz88MMYDMUPS06aNImkpCTzLS4uzo49FkII52Wq67Jsb4L5C/TPvQnc8dl6DiQkU8PLjdmPdGFC/2YY9BU7TfNIr4b8Z0AzAN7+4yBR207Z7NxGo8bnq44x4pvNnE/JommQN0ue6cld7esU+xq9XsctLWsx57Fu/PFcL+7uUAeDXsfvexK49ZO1/HvobJn68dv2OHq++y93fr6eK+nlC3xE0ZwiYAkMDGTRokWkpaVx8uRJDh06hLe3Nw0bNiz2Ne7u7vj6+ha6CSGEgD7N1LRQQlImW2Iu8ebS/Tz1y05Ss3Lp3KA6fzzXm95NA+3Wn2dubsITNzUC4OUFe68b+SmLK+nZPDp7Ox+sOIxRg7vD67D4mZ40CbJ8/6fWIX58NKw9C5/uQZMgb86nZPHIrO28NG8PKZk5Fp1jW+wl7vp8Ay/M20N8Uib7ziTz5M87yM41lvWjiWI4RcBi4uHhQZ06dcjNzWX+/Pncddddju6SEEJUOh6uBgbkTws9PGsrP2yIBeCJPo2Y81g3avt5lPBq29PpdLw8sAUju9ZD0+C/v+3m2LmUMp8vPTuX+2du5t9D53Bz0TP17rZMGxZGNbeypWW2q+vP78/24tFeDdHpIGp7HLd/so5Nxy8W+5q4S+mMm7OT+77axN4zSfi4uzCuX2O83V3YfOISryzcKztn25jVAUtqairR0dFER0cDEBMTQ3R0NKdOqWG+SZMmMWrUqEKvMbVPTU3l/PnzREdHc+DAAfPzW7ZsYcGCBZw4cYJ169Zx++23YzQaefHFF8vx0YQQ4sY1uF0IAJk5Rvw8Xfl2VCcmDWzpsEJuOp2Ot+5qQ68mNcnIyeOZObvIzMmz+jyapvHKgr0cPptCoI87C57qwQNd6pV7BZKHq4FX72jFr491IzTAkzNXMnjgm828uXR/oX6mZeXywYpD3PLRGv7Yk4BeByO61mPVC3154bYWfDYiHL0O5u04zRerj5erT6Iwq5c1r169mn79+l13fPTo0cyaNYsxY8YQGxvL6tWrC96kiH9I9evXJzY2FoA1a9bw1FNPceLECby9vRk0aBDvvvsuISEhFvdLljULIUSBrNw8Hvh6M64GPR/eF0ZoQDVHdwlQq3kGTV/HhdRsHupWn/8NaWPV63/ZcpLJC/dh0OuIfKybzfd/AkjNyuWdPw4SuVX9Id4o0IsP7wvj+LlU3l9xmPMpaoVq90Y1eD2iFS2DC3/n/LQpltcW7wfgswfCiQiz/LvsRmTp97eU5hdCCGFXa46cZ/T3WwH46sEO3N7GsiJ6e08ncc+XG8nOMzJpYAue6NO4IrvJqsPneGneHs6lZBU6Xr9GNSYPasmAVrWKHdl5a+kBvt8Qg5uLnsjHutGxfvUi24kKLM0vhBBClEefZoE80Ucl4b44bw9xl9JLfU1Seg5Pz9lBdp6RAa1q8Xh+Em9F6tc8iL+ev4k780dIfNxdeGVQC/56/iZubV27xGmoyYNb0r9lLbJzjTw+ezunLpb+GUXJZIRFCCGE3eXkGbnvq01Ex12hQz1/op7oXmx+jaZpPDZ7B38fPEtogCe/P9sbP0/rtgwor31nkqjj70l1K3b1TsvKZdjMTeyPT6ZxoBcLnu5p935XBjLCIoQQwmm5GvR89kA4Ph4u7Dx1hY9XHim27ddrT/D3wbO4uej5cmRHh3zpt6njZ1WwAuDl7sJ3oztT29eD4+fTePqXHeTklbzcOSkjh38PneXXrafKlJR8tQupWUycG83CXafLdR5nISMsQgghHOaPPQmMm7MTnQ5mP9LluvowW05cZMS3W8gzakwZ2pYRXes5qKdltz8+ifu+2kR6dh73dwrl3XsKNoNMSMpga8wltsdeZlvsJQ6fTcH0rTyobW1mPNABfRmK+2Xl5jHymy1sP3kZvQ4WPN2z1M0wHUWSboUQQlQKryzcy5wtp6jp7cay8b0J8lF1Ys6nZDH403WcS8liaHgdPhoWZtddn23p30NnefTH7Rg1GN45lKxcI9tiL3H6csZ1bRvW9OL05XRy8jSe6tuYl25vYdV7aZrGi/P28NuOgpGVxoFe/PFc70LbFTgLmRISQghRKbx+Ryua1/LhQmo2/5m7G6NRI8+o8VzkLs6lZNGsljfvDG1TaYMVgJtb1DLvq/TrtjgW7jrD6csZ6HXQto4fj/RsyJcjO7Btcn9W/bcv793TDoAvVx9n7jbrtp75bn0Mv+04jV4Hnz4QTqCPO8fPp/FRCdNulYFT7NYshBDixuXhamDGiHAiZqxn3dELfLX2OOlZeebNDL8Y2aHMVWydyZieDUnLzmPziYuEh/rTqUEAHepXx9v9+s92d4e6xF5I49N/j/HKwr3Ure5JjyY1S32PVYfOMWXZQQBeHdyKO8NC8HIzMPbH7Xyz7gS3tqpFpwa2r11jDzIlJIQQwilEbTvFS/P3YtDryMvftPHTB8LNy4pvNJqmMf7XaJbsjsfXw4UFT/ekSZB3se2Pnk3h7i82kpKVywNdQpkytCBX5r+/7WbejtM0qFGNZeN7O1UAKFNCQgghKpVhnUKJCAsxByujute/YYMVUFXi37+3HR3rVyc5M5dHZm3jYmpWkW0vp2Uz9sftpGTl0qVhAG/eWXgK7bU7WlHb14PYi+m8v/ywvT6CTUnAIoQQwinodDqmDG1D76Y1Gdw2mMmDWzq6Sw7n4Wrg64c6Ui+gGqcupfP4TzuuW+6ck2fkqV92cOpSOqEBnnz1YEfcXAp/vft5uvLevSovZtbG2BI3dnRWErAIIYRwGj4ervw0tiufj+yAu4vzrWhxhBre7nw/pjM+Hi7sOHmZF+ftMe8ErWka/7dkP5tPXMLLzcB3ozsTUEy9mD7NAnmgi1oW/sK83aRm5drtM9iCBCxCCCGEk2sS5M3MBzviotexZHc8H/99FIDZm04yZ8spdPkrgprV8inxPJMHt6SOvyenL2eYk3MrCwlYhBBCiEqgR5OavDNU7W796T9HeWPJft76/QAAL9/eglta1ir1HN7uLnxwn5oamrPlFGuPnK+4DtuYBCxCCCFEJXF/53o8mb9L9ayNseQZNe7pUNeqzSB7NK7J6O71AXhp/h6SM3MqpK+2JgGLEEIIUYm8eFtzBrWtDUCHev5Mudv6onovDWxB/RrVSEjK5H9LD1REN21O6rAIIYQQlUxOnpGNxy/SpUEAnm5lS07eFnuJYTM3oWnw3ehOFk0pVQSpwyKEEEJUUa4GPX2aBZY5WAHo3CCAsT0bAjAhKppftpzEaHTeMQwJWIQQQogb1H9va054PX9SMnOZvHAfQ7/cyN7TSY7uVpEkYBFCCCFuUB6uBn57ojuv39EKb3cXdsdd4c7P1/Paon0kpTtXMq4ELEIIIcQNzMWg55FeDfn3P324q30ImgY/bT7JzdNWM3/HaZwl1VUCFiGEEEIQ5OvB9OHhzHm0K40DvbiYls1/ftvN/TM3czgxxdHdk4BFCCGEEAV6NKnJn+Nv4qXbW+DpamBr7CUGfbqOd/444NBy/hKwCCGEEKIQNxc9T/VtzN//6cNtrWuRZ9T4Zl0MK/YlOqxPLg57ZyGEEEI4tTr+nsx8qBOrDp1jUfQZhobXcVhfJGARQgghRIn6tQiiX4sgh/ZBpoSEEEII4fQkYBFCCCGE05OARQghhBBOTwIWIYQQQjg9CViEEEII4fQkYBFCCCGE07M6YFm7di0RERGEhISg0+lYtGhRie0TEhIYMWIEzZs3R6/XM2HChCLbffLJJzRv3hxPT09CQ0N5/vnnyczMtLZ7QgghhKiCrA5Y0tLSCAsLY8aMGRa1z8rKIjAwkMmTJxMWFlZkm19++YWXX36Z//u//+PgwYN89913REVFMWnSJGu7J4QQQogqyOrCcQMHDmTgwIEWt2/QoAHTp08H4Pvvvy+yzaZNm+jZsycjRowwv+aBBx5g69at1nZPCCGEEFWQU+Sw9OrVix07dpgDlBMnTrBs2TIGDx5c7GuysrJITk4udBNCCCFE1eQUpfmHDx/O+fPn6dWrF5qmkZuby1NPPcXLL79c7GumTp3Km2++acdeCiGEEMJRnGKEZfXq1bzzzjt88cUX7Ny5kwULFvD777/zv//9r9jXTJo0iaSkJPMtLi7Ojj0WQgghhD05xQjLa6+9xkMPPcSjjz4KQNu2bUlLS+Pxxx9n8uTJ6PXXx1Xu7u64u7vbu6tCCCGEcACnCFjS09OvC0oMBgOapqFpmkXnMLWTXBYhhBCi8jB9b5f2fW91wJKamsqxY8fMP8fExBAdHU1AQAD16tVj0qRJnDlzhtmzZ5vbREdHm197/vx5oqOjcXNzo1WrVgBERETw0UcfER4eTteuXTl27BivvfYad955JwaDwaJ+paSkABAaGmrtRxJCCCGEg6WkpODn51fs8zrN0iGMfKtXr6Zfv37XHR89ejSzZs1izJgxxMbGsnr16oI30emua1+/fn1iY2MByM3N5Z133uGnn37izJkzBAYGEhERwTvvvIO/v79F/TIajcTHx+Pj41Pk+5VVcnIyoaGhxMXF4evra7PziqLJ9bYvud72JdfbvuR621dZr7emaaSkpBASElJkCoiJ1QHLjSY5ORk/Pz+SkpLkH7wdyPW2L7ne9iXX277kettXRV9vp1glJIQQQghREglYhBBCCOH0JGAphbu7O//3f/8nS6jtRK63fcn1ti+53vYl19u+Kvp6Sw6LEEIIIZyejLAIIYQQwulJwCKEEEIIpycBixBCCCGcngQsQgghhHB6ErCU4osvvqBhw4Z4eHjQsWNH1q1b5+guVQlr164lIiKCkJAQdDodixYtKvS8pmm88cYbhISE4OnpSd++fdm/f79jOlvJTZ06lc6dO+Pj40NQUBBDhgzh8OHDhdrI9batL7/8knbt2uHr64uvry/du3fnzz//ND8v17viTJ06FZ1Ox4QJE8zH5Hrb1htvvIFOpyt0q127tvn5irreErCUICoqigkTJjB58mR27dpF7969GThwIKdOnXJ01yq9tLQ0wsLCmDFjRpHPv//++3z00UfMmDGDbdu2Ubt2bQYMGGDeM0pYbs2aNYwbN47NmzezcuVKcnNzufXWW0lLSzO3kettW3Xr1uXdd99l+/btbN++nZtvvpm77rrL/EtbrnfF2LZtG19//TXt2rUrdFyut+21bt2ahIQE823v3r3m5yrsemuiWF26dNGefPLJQsdatGihvfzyyw7qUdUEaAsXLjT/bDQatdq1a2vvvvuu+VhmZqbm5+enffXVVw7oYdVy7tw5DdDWrFmjaZpcb3upXr269u2338r1riApKSla06ZNtZUrV2p9+vTRxo8fr2ma/PuuCP/3f/+nhYWFFflcRV5vGWEpRnZ2Njt27ODWW28tdPzWW29l48aNDurVjSEmJobExMRC197d3Z0+ffrItbeBpKQkAAICAgC53hUtLy+PX3/9lbS0NLp37y7Xu4KMGzeOwYMH079//0LH5XpXjKNHjxISEkLDhg0ZPnw4J06cACr2eruU69VV2IULF8jLy6NWrVqFjteqVYvExEQH9erGYLq+RV37kydPOqJLVYamaUycOJFevXrRpk0bQK53Rdm7dy/du3cnMzMTb29vFi5cSKtWrcy/tOV6286vv/7Kzp072bZt23XPyb9v2+vatSuzZ8+mWbNmnD17lrfffpsePXqwf//+Cr3eErCUQqfTFfpZ07TrjomKIdfe9p555hn27NnD+vXrr3tOrrdtNW/enOjoaK5cucL8+fMZPXo0a9asMT8v19s24uLiGD9+PH/99RceHh7FtpPrbTsDBw40P27bti3du3encePG/Pjjj3Tr1g2omOstU0LFqFmzJgaD4brRlHPnzl0XOQrbMmWby7W3rWeffZYlS5awatUq6tataz4u17tiuLm50aRJEzp16sTUqVMJCwtj+vTpcr1tbMeOHZw7d46OHTvi4uKCi4sLa9as4dNPP8XFxcV8TeV6VxwvLy/atm3L0aNHK/TftwQsxXBzc6Njx46sXLmy0PGVK1fSo0cPB/XqxtCwYUNq165d6NpnZ2ezZs0aufZloGkazzzzDAsWLODff/+lYcOGhZ6X620fmqaRlZUl19vGbrnlFvbu3Ut0dLT51qlTJ0aOHEl0dDSNGjWS613BsrKyOHjwIMHBwRX777tcKbtV3K+//qq5urpq3333nXbgwAFtwoQJmpeXlxYbG+vorlV6KSkp2q5du7Rdu3ZpgPbRRx9pu3bt0k6ePKlpmqa9++67mp+fn7ZgwQJt79692gMPPKAFBwdrycnJDu555fPUU09pfn5+2urVq7WEhATzLT093dxGrrdtTZo0SVu7dq0WExOj7dmzR3vllVc0vV6v/fXXX5qmyfWuaFevEtI0ud629p///EdbvXq1duLECW3z5s3aHXfcofn4+Ji/GyvqekvAUorPP/9cq1+/vubm5qZ16NDBvBRUlM+qVas04Lrb6NGjNU1TS+P+7//+T6tdu7bm7u6u3XTTTdrevXsd2+lKqqjrDGg//PCDuY1cb9t65JFHzL83AgMDtVtuucUcrGiaXO+Kdm3AItfbtu6//34tODhYc3V11UJCQrS7775b279/v/n5irreOk3TtPKN0QghhBBCVCzJYRFCCCGE05OARQghhBBOTwIWIYQQQjg9CViEEEII4fQkYBFCCCGE05OARQghhBBOTwIWIYQQQjg9CViEEEII4fQkYBFCCCGE05OARQghhBBOTwIWIYQQQjg9CViEEEII4fT+H+pcXD2YGfAMAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 50\nfile_path = Path(\"/kaggle/input/california-spatial-temporal-fire-dataset/numpy_california_spatialtemporal_dataset.npy\")\nnumpy_array = np.load(file_path)[:,:,700:,:]\ndataloader = temporal_dataloader(numpy_array, sequence_length, batch_size, radius = 2, train_or_test = False, pin_memory = False, num_workers=0)\nf1, recall, precision, auprc, aucroc, accuracy, samples, loss, loss_samples = evaluate_model(ConvTranModel, dataloader, criterion, device)\ndel numpy_array\ndel dataloader\n\nprint(f'epoch #{epoch}:')\nprint(f'val_loss: {loss/loss_samples}!')\nprint(f'f1: {f1/samples}')\nprint(f'recall: {recall/samples}')\nprint(f'precision: {precision/samples}')\nprint(f'auprc: {auprc/samples}')\nprint(f'aucroc: {aucroc/samples}')\nprint(f'accuracy: {accuracy/samples}')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T17:49:12.845055Z","iopub.status.idle":"2023-07-03T17:49:12.845795Z","shell.execute_reply.started":"2023-07-03T17:49:12.845541Z","shell.execute_reply":"2023-07-03T17:49:12.845565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}